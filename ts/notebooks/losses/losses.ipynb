{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f2ec8b-7eca-4657-9616-a4d15c00441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4accd365-e165-4f82-be9b-99ddf2178f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([float(\"nan\"), float(\"inf\"), -float(\"inf\"), 3.14])\n",
    "torch.nan_to_num(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b584fb-2491-4ef0-abb7-a683e4820473",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(100)\n",
    "yhat = torch.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcdbe5-ac87-46ba-a30b-f81386d1943e",
   "metadata": {},
   "source": [
    "### Scale-dependent Errors\n",
    "### 1. **Mean Absolute Error (MAE)**:\n",
    "#### Formula:\n",
    "$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right| $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "import torch\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return torch.sum(torch.abs(y - yhat)) / len(y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Mean Squared Error (MSE)**:\n",
    "#### Formula:\n",
    "$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def mse(y, yhat):\n",
    "    return torch.sum(torch.square(y - yhat)) / len(y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Root Mean Squared Error (RMSE)**:\n",
    "#### Formula:\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def rmse(y, yhat):\n",
    "    return torch.sqrt(torch.sum(torch.square(y - yhat)) / len(y))\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3eba9-58b2-4bc4-8bd2-d392fc29217d",
   "metadata": {},
   "source": [
    "### Scale-independent Errors\n",
    "### 4. **Mean Absolute Percentage Error (MAPE)**:\n",
    "#### Formula:\n",
    "$ \\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100 $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def mape(y, yhat):\n",
    "    return (torch.sum(torch.abs((y - yhat) / y)) / len(y)) * 100\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Symmetric Mean Absolute Percentage Error (SMAPE)**:\n",
    "#### Formula:\n",
    "$ \\text{SMAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{2 \\left| y_i - \\hat{y}_i \\right|}{\\left| y_i \\right| + \\left| \\hat{y}_i \\right|} $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def smape(y, yhat):\n",
    "    return torch.sum(torch.abs(y - yhat) / ((torch.abs(y) + torch.abs(yhat)) / 2)) / len(y)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef41222-bc61-4eb0-9f29-378079ec7ddc",
   "metadata": {},
   "source": [
    "### Scale-independent Errors\n",
    "### 6. **Mean Absolute Scaled Error (MASE)**:\n",
    "#### Formula:\n",
    "$ \\text{MASE} = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|}{\\frac{1}{n-1} \\sum_{i=2}^{n} \\left| y_i - y_{i-1} \\right|} $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ n $ is the number of data points,\n",
    "- The denominator is the MAE of a naive model using previous values.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def mase(y, yhat):\n",
    "    # Compute the MAE of the model\n",
    "    mae_model = torch.sum(torch.abs(y - yhat)) / len(y)\n",
    "    \n",
    "    # Compute the MAE of the naive model (y_t = y_(t-1))\n",
    "    naive_error = torch.sum(torch.abs(y[1:] - y[:-1])) / (len(y) - 1)\n",
    "    \n",
    "    # Compute MASE\n",
    "    return mae_model / naive_error\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Relative Mean Squared Error (relMSE)**:\n",
    "#### Formula:\n",
    "$ \\text{relMSE} = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "Where:\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ \\bar{y} $ is the mean of the actual values.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def rel_mse(y, yhat):\n",
    "    # Compute the MSE of the model\n",
    "    mse_model = torch.sum(torch.square(y - yhat)) / len(y)\n",
    "    \n",
    "    # Compute the variance of the true values (y)\n",
    "    variance_y = torch.sum(torch.square(y - torch.mean(y))) / len(y)\n",
    "    \n",
    "    # Compute relMSE\n",
    "    return mse_model / variance_y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820aac66-0b76-4989-bc73-4db5891994d8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. **Quantile Loss**:\n",
    "#### Formula:\n",
    "$ \\text{Quantile Loss}(q) = \\begin{cases} q \\cdot (y - \\hat{y}) & \\text{if } y \\geq \\hat{y} \\\\ (1 - q) \\cdot (\\hat{y} - y) & \\text{if } y < \\hat{y} \\end{cases} $\n",
    "Where:\n",
    "- $ y $ is the true value,\n",
    "- $ \\hat{y} $ is the predicted value,\n",
    "- $ q $ is the quantile being predicted.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "import torch\n",
    "\n",
    "def quantile_loss(y, yhat, q):\n",
    "    # Calculate the quantile loss\n",
    "    loss = torch.max(q * (y - yhat), (q - 1) * (y - yhat))\n",
    "    return torch.mean(loss)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Multi-Quantile Loss (MQLoss)**:\n",
    "#### Formula:\n",
    "$ \\text{MQLoss}(y, \\hat{y}, Q) = \\frac{1}{k} \\sum_{i=1}^{k} \\text{Quantile Loss}(q_i) $\n",
    "Where:\n",
    "- $ Q = \\{q_1, q_2, \\dots, q_k\\} $ is the set of quantiles,\n",
    "- $ q_i $ is the $ i $-th quantile in the set.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def multi_quantile_loss(y, yhat, quantiles):\n",
    "    losses = []\n",
    "    for q in quantiles:\n",
    "        loss = torch.max(q * (y - yhat), (q - 1) * (y - yhat))\n",
    "        losses.append(torch.mean(loss))\n",
    "    return torch.mean(torch.stack(losses))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Implicit Quantile Loss (IQLoss)**:\n",
    "#### Formula:\n",
    "$ \\text{IQLoss} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\hat{y}_i - y_i \\right| \\times \\text{weight} $\n",
    "Where:\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ y_i $ is the true value,\n",
    "- The weight depends on the quantiles and is dynamically calculated.\n",
    "\n",
    "#### Torch Implementation:\n",
    "```python\n",
    "def implicit_quantile_loss(y, yhat, quantiles):\n",
    "    losses = []\n",
    "    for q in quantiles:\n",
    "        diff = y - yhat\n",
    "        weight = torch.where(diff >= 0, q, 1 - q)\n",
    "        loss = weight * torch.abs(diff)\n",
    "        losses.append(torch.mean(loss))\n",
    "    return torch.mean(torch.stack(losses))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Distribution Loss (DistributionLoss)**:\n",
    "#### Formula (using Kullback-Leibler Divergence):\n",
    "$ \\text{KL}(p || q) = \\sum_{i=1}^{n} p(y_i) \\log \\frac{p(y_i)}{q(\\hat{y}_i)} $\n",
    "Where:\n",
    "- $ p(y_i) $ is the true distribution of the target variable,\n",
    "- $ q(\\hat{y}_i) $ is the predicted distribution.\n",
    "\n",
    "#### Torch Implementation (KL Divergence):\n",
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def distribution_loss(y, yhat, p_dist, q_dist):\n",
    "    # Calculate KL divergence between true distribution p and predicted q\n",
    "    kl_loss = F.kl_div(q_dist.log(), p_dist, reduction='batchmean')\n",
    "    return kl_loss\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cb640-b0d5-4f76-a24c-e88f242029f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
