# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/training/training.nbeats.ipynb.

# %% auto 0
__all__ = ['df', 'input_size', 'horizon', 'batch_size', 'num_workers', 'step_size', 'ds', 'profiler', 'trainer', 'model']

# %% ../../nbs/training/training.nbeats.ipynb 1
from datasetsforecast.m3 import M3

df = M3().load("../data", group="Monthly")[0]
df.sort_values(["unique_id", "ds"], inplace=True)
df

# %% ../../nbs/training/training.nbeats.ipynb 4
from ..preprocess.dataloader import UnivariateTSDataModule

# %% ../../nbs/training/training.nbeats.ipynb 5
input_size = 60
horizon = 12
batch_size = 512
num_workers = 24
step_size = 3

ds = UnivariateTSDataModule(
    df=df,
    input_size=input_size,
    horizon=horizon,
    batch_size=batch_size,
    num_workers=num_workers,
    train_split=0.7,
    val_split=0.15,
    normalize=True,
    scaler_type="minmax",
    split_type="vertical",
    step_size=step_size,
)


# %% ../../nbs/training/training.nbeats.ipynb 6
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger

from ..model.nbeats import NBeatsG

# %% ../../nbs/training/training.nbeats.ipynb 7
from pytorch_lightning.profilers import AdvancedProfiler

profiler = AdvancedProfiler(dirpath=".", filename="memory_profile.txt")

# Example trainer setup (without full NBeatsG for brevity)
trainer = pl.Trainer(
    max_epochs=200,  # Short run for testing
    accelerator="auto",
    logger=TensorBoardLogger("M4_logs", name="nbeatsg_m3_monthly"),
    callbacks=[EarlyStopping("val_loss", patience=20, verbose=False)],
    # profiler=profiler
)

model = NBeatsG(input_size=input_size, horizon=horizon)
trainer.fit(model, ds)

# %% ../../nbs/training/training.nbeats.ipynb 8
trainer.test(model, ds);

# %% ../../nbs/training/training.nbeats.ipynb 10
trainer.save_checkpoint('M3-MONTHLY-profile.ckpt')
