{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b29d6e-ad74-421a-b548-b3b2f52bec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>1</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>2</td>\n",
       "      <td>8350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1</td>\n",
       "      <td>3</td>\n",
       "      <td>8570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>4</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>5</td>\n",
       "      <td>7080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246406</th>\n",
       "      <td>M9999</td>\n",
       "      <td>83</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246407</th>\n",
       "      <td>M9999</td>\n",
       "      <td>84</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246408</th>\n",
       "      <td>M9999</td>\n",
       "      <td>85</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246409</th>\n",
       "      <td>M9999</td>\n",
       "      <td>86</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246410</th>\n",
       "      <td>M9999</td>\n",
       "      <td>87</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11246411 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id  ds       y\n",
       "0               M1   1  8000.0\n",
       "1               M1   2  8350.0\n",
       "2               M1   3  8570.0\n",
       "3               M1   4  7700.0\n",
       "4               M1   5  7080.0\n",
       "...            ...  ..     ...\n",
       "11246406     M9999  83  4200.0\n",
       "11246407     M9999  84  4300.0\n",
       "11246408     M9999  85  3800.0\n",
       "11246409     M9999  86  4400.0\n",
       "11246410     M9999  87  4300.0\n",
       "\n",
       "[11246411 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasetsforecast.m4 import M4\n",
    "\n",
    "df = M4().load(\"../data\", group=\"Monthly\")[0]\n",
    "df.sort_values([\"unique_id\", \"ds\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b9ae21-ff35-4d7d-a525-fc9421c426ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90026/393653933.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('unique_id').apply(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48000.000000\n",
       "mean       234.300229\n",
       "std        137.406295\n",
       "min         60.000000\n",
       "25%        100.000000\n",
       "50%        220.000000\n",
       "75%        324.000000\n",
       "max       2812.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"unique_id\").apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6f3c39-add5-4301-8f1c-906a5d474ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts.preprocess.dataloader import UnivariateTSDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52007182-f8d6-4f28-9b5a-db6e7260c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 48\n",
    "horizon = 12\n",
    "batch_size = 512 * 2\n",
    "num_workers = 20\n",
    "\n",
    "ds = UnivariateTSDataModule(\n",
    "    df=df,\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    train_split=0.7,\n",
    "    val_split=0.15,\n",
    "    normalize=True,\n",
    "    scaler_type=\"minmax\",\n",
    "    split_type=\"vertical\",\n",
    "    step_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee22850-d3e7-42aa-aa22-41153a93a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from ts.model.nbeats import NBeatsG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9094f4f-3cd7-4c42-93e9-8a887f1adfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:ts.preprocess.dataloader:Train windows: 5891975, Val windows: 1241277, Test windows: 1281159\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type                                 | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | stacks  | ModuleList                           | 61.1 M | train\n",
      "1 | loss_fn | MSELoss                              | 0      | train\n",
      "2 | smape   | SymmetricMeanAbsolutePercentageError | 0      | train\n",
      "3 | mase    | MASE                                 | 0      | train\n",
      "4 | owa     | OWA                                  | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "61.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "61.1 M    Total params\n",
      "244.557   Total estimated model params size (MB)\n",
      "1025      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67c07ed814a43e89386f143886e9b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c90d3be3e7746a6b997ce5ef63fda5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b80e88b071e4d5197fe5bd58b31c355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example trainer setup (without full NBeatsG for brevity)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,  # Short run for testing\n",
    "    accelerator=\"auto\",\n",
    "    logger=TensorBoardLogger(\"logs\", name=\"nbeatsg_m3_monthly\"),\n",
    "    callbacks=[EarlyStopping(\"val_loss\", patience=10, verbose=False)],\n",
    ")\n",
    "model = NBeatsG(input_size=input_size, horizon=horizon)\n",
    "trainer.fit(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ea427-8652-49a5-91c5-975ff273f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02ad1a-ee07-45c1-9a07-45ae3d6b326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Function to forecast and plot in a 3x2 grid without legend\n",
    "\n",
    "\n",
    "def forecast_and_plot_grid(trainer, model, data_module, num_series=6):\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get all unique_ids from the DataFrame\n",
    "    unique_ids = data_module.df[\"unique_id\"].unique()\n",
    "    # Randomly select 6 unique_ids (or fewer if less available)\n",
    "    selected_ids = np.random.choice(\n",
    "        unique_ids, size=min(num_series, len(unique_ids)), replace=False\n",
    "    )\n",
    "\n",
    "    # Prepare test data for selected series\n",
    "    test_data = data_module.df[data_module.df[\"unique_id\"].isin(selected_ids)]\n",
    "    grouped = test_data.groupby(\"unique_id\")\n",
    "\n",
    "    # Create figure with 3x2 grid\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=2,\n",
    "        subplot_titles=[f\"Series: {uid}\" for uid in selected_ids],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.1,\n",
    "    )\n",
    "\n",
    "    # Perform forecasting and plotting\n",
    "    for i, unique_id in enumerate(selected_ids):\n",
    "        series = grouped.get_group(unique_id)[\"y\"].values\n",
    "        series_len = len(series)\n",
    "\n",
    "        if series_len < data_module.input_size + data_module.horizon:\n",
    "            print(f\"Skipping {unique_id}: too short for forecasting\")\n",
    "            continue\n",
    "\n",
    "        # Normalize series if data_module uses normalization\n",
    "        if data_module.normalize:\n",
    "            scaler = data_module.scalers.get(unique_id)\n",
    "            if scaler:\n",
    "                series_normalized = scaler.transform(series.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                series_normalized = series\n",
    "        else:\n",
    "            series_normalized = series\n",
    "\n",
    "        # Generate last input window for forecasting\n",
    "        last_input = series_normalized[\n",
    "            -data_module.input_size - data_module.horizon : -data_module.horizon\n",
    "        ]\n",
    "        x = torch.tensor(last_input, dtype=torch.float32).unsqueeze(0).to(model.device)\n",
    "\n",
    "        # Forecast\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x).cpu().numpy().flatten()\n",
    "\n",
    "        # Inverse transform predictions and actual values\n",
    "        if data_module.normalize and scaler:\n",
    "            y_hat_denorm = scaler.inverse_transform(y_hat.reshape(-1, 1)).flatten()\n",
    "            y_true_denorm = series[-data_module.horizon :]\n",
    "        else:\n",
    "            y_hat_denorm = y_hat\n",
    "            y_true_denorm = series[-data_module.horizon :]\n",
    "\n",
    "        # Time indices for plotting\n",
    "        time_indices = pd.date_range(\n",
    "            start=grouped.get_group(unique_id)[\"ds\"].iloc[-data_module.horizon],\n",
    "            periods=data_module.horizon,\n",
    "            freq=\"M\",\n",
    "        )\n",
    "\n",
    "        # Determine row and column (0-based indexing, converting to 1-based for Plotly)\n",
    "        row = (i // 2) + 1\n",
    "        col = (i % 2) + 1\n",
    "\n",
    "        # Plot actual values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=time_indices,\n",
    "                y=y_true_denorm,\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(color=\"blue\"),\n",
    "                showlegend=False,\n",
    "            ),  # No legend\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        # Plot predicted values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=time_indices,\n",
    "                y=y_hat_denorm,\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(color=\"red\", dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "            ),  # No legend\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        width=800,  # Fixed size for 3x2 grid\n",
    "        title_text=\"N-BEATS-G Forecasting Results (3x2 Grid)\",\n",
    "        showlegend=False,  # Remove legend entirely\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Value\")\n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Example usage (assuming trainer, model, and data_module are defined)\n",
    "# forecast_and_plot_grid(trainer, model, data_module, num_series=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd293fc-4437-4ceb-b1f5-f056280dd1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb2c12-22c5-49af-ae43-a87fffcdc5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdceabd-13ad-4ff0-a933-3731b2f85545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
