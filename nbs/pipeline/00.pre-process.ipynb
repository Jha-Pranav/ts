{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c827a4dc-b067-4c4c-b2e1-1cd2bdf83778",
   "metadata": {
    "papermill": {
     "duration": 1.493231,
     "end_time": "2025-05-02T11:32:48.051635",
     "exception": false,
     "start_time": "2025-05-02T11:32:46.558404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasetsforecast.m5 import M5\n",
    "\n",
    "df = M5().load(\"../data\")[0]  # , group=\"Monthly\"\n",
    "df.sort_values([\"unique_id\", \"ds\"], inplace=True)\n",
    "df.to_parquet(\"data/input/m5.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b3867c-8c3c-4f8a-989e-62093402bf31",
   "metadata": {
    "papermill": {
     "duration": 1.215498,
     "end_time": "2025-05-02T11:32:49.268108",
     "exception": false,
     "start_time": "2025-05-02T11:32:48.052610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10427/3265411083.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for uid, group in tqdm(df.groupby(\"unique_id\"), desc=\"Scaling series\"):\n",
      "Scaling series: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30490/30490 [00:08<00:00, 3584.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scaled data saved to: data/intermediate/m5_scaled.parquet\n",
      "✅ Scaler stats saved to: artifacts/m5_scalers.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Config ===\n",
    "input_path = \"data/input/m5.parquet\"\n",
    "output_path = \"data/intermediate/m5_scaled.parquet\"\n",
    "scaler_save_path = \"artifacts/m5_scalers.json\"\n",
    "scaler = \"minmax\"  # or \"standard\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_parquet(input_path)\n",
    "scaled_parts = []\n",
    "scaler_stats = {}\n",
    "\n",
    "# === Process per unique_id with tqdm ===\n",
    "for uid, group in tqdm(df.groupby(\"unique_id\"), desc=\"Scaling series\"):\n",
    "    y = torch.tensor(group[\"y\"].values, dtype=torch.float32, device=device)\n",
    "\n",
    "    if scaler == \"minmax\":\n",
    "        min_val, max_val = y.min(), y.max()\n",
    "        scaled_y = (y - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "        scaler_stats[uid] = {\n",
    "            \"type\": \"minmax\",\n",
    "            \"min\": float(min_val.cpu()),\n",
    "            \"max\": float(max_val.cpu()),\n",
    "        }\n",
    "\n",
    "    elif scaler == \"standard\":\n",
    "        mean, std = y.mean(), y.std(unbiased=False)\n",
    "        scaled_y = (y - mean) / (std + 1e-8)\n",
    "\n",
    "        scaler_stats[uid] = {\n",
    "            \"type\": \"standard\",\n",
    "            \"mean\": float(mean.cpu()),\n",
    "            \"std\": float(std.cpu()),\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scaler type: {scaler}\")\n",
    "\n",
    "    group = group.copy()\n",
    "    group[\"y_scaled\"] = scaled_y.cpu().numpy()\n",
    "    scaled_parts.append(group)\n",
    "\n",
    "# === Save Scaled Data and Scaler Stats ===\n",
    "scaled_df = pd.concat(scaled_parts).sort_values([\"unique_id\", \"ds\"])\n",
    "scaled_df.to_parquet(output_path, index=False)\n",
    "\n",
    "with open(scaler_save_path, \"w\") as f:\n",
    "    json.dump(scaler_stats, f, indent=2)\n",
    "\n",
    "print(f\"✅ Scaled data saved to: {output_path}\")\n",
    "print(f\"✅ Scaler stats saved to: {scaler_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fb0db-db26-432e-98da-85213bdd9e56",
   "metadata": {
    "papermill": {
     "duration": 0.000815,
     "end_time": "2025-05-02T11:32:49.270032",
     "exception": false,
     "start_time": "2025-05-02T11:32:49.269217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb1740-a475-4e44-a51c-a2681cb3c5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.683915,
   "end_time": "2025-05-02T11:32:49.685343",
   "environment_variables": {},
   "exception": null,
   "input_path": "00.pre-process.ipynb",
   "output_path": "00.pre-process.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T11:32:46.001428",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
