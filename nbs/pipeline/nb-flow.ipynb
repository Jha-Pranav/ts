{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b42d5f-49d8-432f-a910-c8a16cae1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”œâ”€â”€ 00.pre-process.ipynb\n",
    "# â”œâ”€â”€ 01.clustering.ipynb\n",
    "# â”œâ”€â”€ 02.training.ipynb\n",
    "# â”œâ”€â”€ 03.inference-preprocess.ipynb\n",
    "# â”œâ”€â”€ 05.post-processing.ipynb\n",
    "# â”œâ”€â”€ 06.inference.ipynb\n",
    "# â”œâ”€â”€ 07.evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e224c28-3b78-47e8-8f16-8a5088956afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ensured directory exists: data/input\n",
      "âœ… Ensured directory exists: data/intermediate\n",
      "âœ… Ensured directory exists: artifacts\n",
      "âœ… Ensured directory exists: data/output\n",
      "âœ… Ensured directory exists: checkpoints\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "paths = [\"data/input\", \"data/intermediate\", \"artifacts\", \"data/output\", \"checkpoints\"]\n",
    "\n",
    "for path in paths:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(f\"âœ… Ensured directory exists: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e5e133f-7e46-4d5c-8de2-eab4c758eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ““ Running notebook: 00.pre-process.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceb1f7400074145aa154aaf8304ec59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/datasetsforecast/m3.py:108: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(class_group.freq)\n",
      "\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/datasetsforecast/m3.py:108: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(class_group.freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling series:   0%|          | 0/1428 [00:00<?, ?it/s]\n",
      "Scaling series:   0%|          | 1/1428 [00:00<03:11,  7.46it/s]\n",
      "Scaling series:  32%|â–ˆâ–ˆâ–ˆâ–      | 453/1428 [00:00<00:00, 2333.18it/s]\n",
      "Scaling series:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 908/1428 [00:00<00:00, 3270.63it/s]\n",
      "Scaling series:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1260/1428 [00:00<00:00, 3127.67it/s]\n",
      "Scaling series: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1428/1428 [00:00<00:00, 2880.93it/s]\n",
      "Scaling series: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1428/1428 [00:00<00:00, 2880.93it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scaled data saved to: data/intermediate/m3-monthly_scaled.parquet\n",
      "âœ… Scaler stats saved to: artifacts/m3-monthly_scalers.json\n",
      "âœ… Done: executed/00.pre-process.ipynb (â±ï¸ 3.71 seconds)\n",
      "\n",
      "ðŸ““ Running notebook: 02.training.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33de0df06985422fae3c9f230ce95030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/pranav-pc/projects/ts/nbs/pipeline/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/pranav-pc/projects/ts/nbs/pipeline/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "  | Name    | Type                                 | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | stacks  | ModuleList                           | 61.9 M | train\n",
      "1 | loss_fn | MSELoss                              | 0      | train\n",
      "2 | smape   | SymmetricMeanAbsolutePercentageError | 0      | train\n",
      "3 | mase    | MASE                                 | 0      | train\n",
      "4 | owa     | OWA                                  | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "61.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "61.9 M    Total params\n",
      "247.741   Total estimated model params size (MB)\n",
      "1025      Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "\n",
      "  | Name    | Type                                 | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | stacks  | ModuleList                           | 61.9 M | train\n",
      "1 | loss_fn | MSELoss                              | 0      | train\n",
      "2 | smape   | SymmetricMeanAbsolutePercentageError | 0      | train\n",
      "3 | mase    | MASE                                 | 0      | train\n",
      "4 | owa     | OWA                                  | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "61.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "61.9 M    Total params\n",
      "247.741   Total estimated model params size (MB)\n",
      "1025      Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 0.013208459131419659, 'test_smape': 0.27940425276756287, 'test_mase': 0.0001561021344969049, 'test_owa': 0.7268368005752563}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'val_loss': 0.01312445942312479, 'val_smape': 0.2746376097202301, 'val_mase': 0.0001552953035570681, 'val_owa': 0.6890231966972351}]\n",
      "âœ… Done: executed/02.training.ipynb (â±ï¸ 92.80 seconds)\n",
      "\n",
      "ðŸ““ Running notebook: 03.inference-preprocess.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4830dd2f91149149cbb09f6a1898a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/5 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_267928/1654867668.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  infer_df = df.groupby(\"unique_id\").apply(extract_series).dropna()\n",
      "\n",
      "/tmp/ipykernel_267928/1654867668.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  infer_df = df.groupby(\"unique_id\").apply(extract_series).dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: executed/03.inference-preprocess.ipynb (â±ï¸ 2.29 seconds)\n",
      "\n",
      "ðŸ““ Running notebook: 04.inference.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf5a6637c4e45378c450b3ae62aae24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/5 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: executed/04.inference.ipynb (â±ï¸ 4.28 seconds)\n",
      "\n",
      "ðŸ““ Running notebook: 05.post-processing.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec8751cf1ee4de78c115eec39072441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/4 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inverting:   0%|          | 0/1108 [00:00<?, ?it/s]\n",
      "Inverting:   5%|â–         | 55/1108 [00:00<00:01, 549.73it/s]\n",
      "Inverting:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 388/1108 [00:00<00:00, 2184.29it/s]\n",
      "Inverting:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 721/1108 [00:00<00:00, 2705.56it/s]\n",
      "Inverting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1054/1108 [00:00<00:00, 2951.77it/s]\n",
      "Inverting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1108/1108 [00:00<00:00, 2658.56it/s]\n",
      "Inverting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1108/1108 [00:00<00:00, 2658.56it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: executed/05.post-processing.ipynb (â±ï¸ 2.29 seconds)\n",
      "\n",
      "ðŸ““ Running notebook: 06.evaluation.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ede52d377c4990a5a9bf9a4a27c45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: executed/06.evaluation.ipynb (â±ï¸ 1.92 seconds)\n",
      "\n",
      "âœ… Flow has completed successfully in 107.28 seconds!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import papermill as pm\n",
    "\n",
    "\n",
    "def run_notebook(input_notebook, output_notebook=None, parameters=None):\n",
    "    try:\n",
    "        print(f\"\\nðŸ““ Running notebook: {input_notebook}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            input_path=input_notebook,\n",
    "            output_path=output_notebook or input_notebook.replace(\".ipynb\", \".executed.ipynb\"),\n",
    "            parameters=parameters or {},\n",
    "            log_output=True,\n",
    "            autosave_cell_every=60,\n",
    "            stdout_file=sys.stdout,\n",
    "            stderr_file=sys.stderr,\n",
    "        )\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print(f\"âœ… Done: {output_notebook or input_notebook} (â±ï¸ {duration:.2f} seconds)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in {input_notebook}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(\"executed\", exist_ok=True)\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    run_notebook(\"00.pre-process.ipynb\", \"executed/00.pre-process.ipynb\")\n",
    "    run_notebook(\"02.training.ipynb\", \"executed/02.training.ipynb\")\n",
    "    run_notebook(\"03.inference-preprocess.ipynb\", \"executed/03.inference-preprocess.ipynb\")\n",
    "    run_notebook(\"04.inference.ipynb\", \"executed/04.inference.ipynb\")\n",
    "    run_notebook(\"05.post-processing.ipynb\", \"executed/05.post-processing.ipynb\")\n",
    "    run_notebook(\"06.evaluation.ipynb\", \"executed/06.evaluation.ipynb\")\n",
    "\n",
    "    total_duration = time.time() - total_start_time\n",
    "    print(f\"\\nâœ… Flow has completed successfully in {total_duration:.2f} seconds!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb05a7c-738b-4d71-a6fb-848b222b1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f81966-239e-4f68-95f4-bef611e60329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook: 00.pre-process.ipynbRunning notebook: 03.post-processing.ipynb\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2157a15730b418096b3521b7b8b29fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132376107e504191a812157a902efc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: 03.post-processing.ipynb\n",
      "âœ… Done: 00.pre-process.ipynb\n",
      "Flow has completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# import papermill as pm\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# def run_notebook(input_notebook, parameters=None):\n",
    "#     \"\"\"\n",
    "#     Executes a notebook without saving the output.\n",
    "\n",
    "#     Args:\n",
    "#         input_notebook (str): Path to the input notebook.\n",
    "#         parameters (dict, optional): Parameters to pass into the notebook.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         print(f\"Running notebook: {input_notebook}\")\n",
    "#         pm.execute_notebook(input_notebook, input_notebook, parameters=parameters or {})\n",
    "#         print(f\"âœ… Done: {input_notebook}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error occurred during notebook execution: {str(e)}\")\n",
    "#         raise e\n",
    "\n",
    "# def main():\n",
    "#     # List of notebooks to run\n",
    "#     notebooks = [\n",
    "#         '00.pre-process.ipynb',\n",
    "#         # '01.feature-engineering.ipynb',\n",
    "#         # '02.model-training.ipynb',\n",
    "#         '03.post-processing.ipynb'\n",
    "#     ]\n",
    "\n",
    "#     # Using ThreadPoolExecutor to run notebooks in parallel\n",
    "#     with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "#         futures = [executor.submit(run_notebook, notebook) for notebook in notebooks]\n",
    "\n",
    "#         # Wait for all futures to complete\n",
    "#         for future in as_completed(futures):\n",
    "#             future.result()  # If any exceptions were raised, it will be propagated here\n",
    "\n",
    "#     print(\"Flow has completed successfully!\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6fa02-38ba-42c2-b3d8-9ce115c70763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
