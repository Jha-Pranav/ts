{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89005aa2-49c1-4377-a9eb-b15dab5cbf2f",
   "metadata": {
    "papermill": {
     "duration": 0.956947,
     "end_time": "2025-05-02T11:32:47.460948",
     "exception": false,
     "start_time": "2025-05-02T11:32:46.504001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def invert_scaling_torch(\n",
    "    scaled_series: torch.Tensor, uid: str, stats_dict: dict, device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    scaler_info = stats_dict.get(uid)\n",
    "    if not scaler_info:\n",
    "        raise ValueError(f\"No scaler info found for unique_id '{uid}'\")\n",
    "\n",
    "    scaled_series = scaled_series.to(device)\n",
    "\n",
    "    if scaler_info[\"type\"] == \"minmax\":\n",
    "        min_val = torch.tensor(scaler_info[\"min\"], dtype=torch.float32, device=device)\n",
    "        max_val = torch.tensor(scaler_info[\"max\"], dtype=torch.float32, device=device)\n",
    "        return scaled_series * (max_val - min_val + 1e-8) + min_val\n",
    "\n",
    "    elif scaler_info[\"type\"] == \"standard\":\n",
    "        mean = torch.tensor(scaler_info[\"mean\"], dtype=torch.float32, device=device)\n",
    "        std = torch.tensor(scaler_info[\"std\"], dtype=torch.float32, device=device)\n",
    "        return scaled_series * (std + 1e-8) + mean\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scaler type: {scaler_info['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5da1ee-6823-446c-b339-8689b9d22b6e",
   "metadata": {
    "papermill": {
     "duration": 0.372726,
     "end_time": "2025-05-02T11:32:47.835235",
     "exception": false,
     "start_time": "2025-05-02T11:32:47.462509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inverting: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1108/1108 [00:00<00:00, 3260.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 356 ms, sys: 2.56 ms, total: 358 ms\n",
      "Wall time: 356 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inverting:  88%|████████▊ | 1262/1428 [00:00<00:00, 4781.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inverting: 100%|██████████| 1428/1428 [00:00<00:00, 4346.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 288 ms, sys: 76.6 ms, total: 365 ms\n",
      "Wall time: 365 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load scaler stats\n",
    "with open(\"artifacts/scalers.json\", \"r\") as f:\n",
    "    stats_dict = json.load(f)\n",
    "\n",
    "# Load scaled data\n",
    "scaled_df = pd.read_parquet(\"data/intermediate/m5_scaled_forecast.parquet\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize an empty Series to collect results\n",
    "y_inverted_series = pd.Series(index=scaled_df.index, dtype=float)\n",
    "yhat_inverted_series = pd.Series(index=scaled_df.index, dtype=float)\n",
    "# Loop through each group with tqdm\n",
    "for uid, group in tqdm(scaled_df.groupby(\"unique_id\", sort=False), desc=\"Inverting\"):\n",
    "    scaled_tensor = torch.tensor(group[\"y_scaled\"].values, dtype=torch.float32)\n",
    "    inverted_tensor = invert_scaling_torch(scaled_tensor, uid, stats_dict, device=device)\n",
    "    y_inverted_series.loc[group.index] = inverted_tensor.cpu().numpy()\n",
    "\n",
    "    scaled_tensor = torch.tensor(group[\"yhat_scaled\"].values, dtype=torch.float32)\n",
    "    inverted_tensor = invert_scaling_torch(scaled_tensor, uid, stats_dict, device=device)\n",
    "    yhat_inverted_series.loc[group.index] = inverted_tensor.cpu().numpy()\n",
    "\n",
    "# Assign back to DataFrame\n",
    "scaled_df[\"y\"] = y_inverted_series\n",
    "scaled_df[\"yhat\"] = yhat_inverted_series\n",
    "scaled_df.to_parquet(\"data/output/m5_forecast.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da0c221-12ec-455f-a26b-4cd0bd22fdc8",
   "metadata": {
    "papermill": {
     "duration": 0.009212,
     "end_time": "2025-05-02T11:32:47.846670",
     "exception": false,
     "start_time": "2025-05-02T11:32:47.837458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a2d31-3283-463c-9e73-ad148fe10dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.160559,
   "end_time": "2025-05-02T11:32:48.162733",
   "environment_variables": {},
   "exception": null,
   "input_path": "03.post-processing.ipynb",
   "output_path": "03.post-processing.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T11:32:46.002174",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
