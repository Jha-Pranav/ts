{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a3b4b-072e-4366-b38c-abd02a728032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# load pretrain model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"thuml/timer-base-84m\", trust_remote_code=True)\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "# # prepare input\n",
    "# batch_size, lookback_length = 1, 2880\n",
    "# seqs = torch.randn(batch_size, lookback_length)\n",
    "\n",
    "# # generate forecast\n",
    "# prediction_length = 96\n",
    "# normed_output = model.(seqs, max_new_tokens=prediction_length)\n",
    "\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431dffe-30d9-4e75-93fa-166ae0abd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/m4_preprocessed.parquet\")\n",
    "# lengths = df.no_of_datapoints.values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df.best_model.values)\n",
    "classes = {idx: class_name for idx, class_name in enumerate(le.classes_)}\n",
    "\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(\n",
    "    scaler.fit_transform(df.drop([\"best_model\", \"no_of_datapoints\"], axis=1).T).T,\n",
    "    columns=df.columns[:-2],\n",
    "    index=df.index,\n",
    ").fillna(0.0)\n",
    "# sequences = torch.tensor(df.values)\n",
    "df[\"best_model\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ff3f8-76ba-4526-bc14-13652fbdf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define the dataset class\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = torch.tensor(df.drop(columns=[\"best_model\"]).values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(\n",
    "            df[\"best_model\"].values, dtype=torch.long\n",
    "        )  # Assuming categorical labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Modify the model for classification\n",
    "\n",
    "\n",
    "class FineTunedTimerForPrediction(pl.LightningModule):\n",
    "    def __init__(self, original_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = original_model.model  # Keep the original feature extractor\n",
    "\n",
    "        # Freeze original model weights\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # New classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Accuracy & F1 Score\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)  # This returns MoeModelOutputWithPast\n",
    "        if hasattr(output, \"last_hidden_state\"):\n",
    "            x = output.last_hidden_state  # Extract the last hidden state tensor\n",
    "        elif isinstance(output, tuple):\n",
    "            x = output[0]  # Extract the first element if it's a tuple\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected model output type: {type(output)}\")\n",
    "\n",
    "        x = self.classification_head(x[:, 0, :])  # Use the first token's embedding if needed\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_function(logits, y)\n",
    "\n",
    "        acc = self.train_acc(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_function(logits, y)\n",
    "\n",
    "        acc = self.val_acc(logits, y)\n",
    "        f1 = self.val_f1(logits, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True)\n",
    "        self.log(\"val_f1\", f1, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.classification_head.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "\n",
    "def get_dataloaders(df, batch_size=512):\n",
    "    dataset = TimeSeriesDataset(df)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=31, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=31, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# Training script\n",
    "\n",
    "\n",
    "def train_model(df, original_model, num_classes=10, epochs=10):\n",
    "    train_loader, val_loader = get_dataloaders(df)\n",
    "\n",
    "    model = FineTunedTimerForPrediction(original_model, num_classes)\n",
    "\n",
    "    # Logging setup\n",
    "    logger = TensorBoardLogger(\"log/\", name=\"TimerClassification\")\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=epochs, accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", logger=logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b4c30-55a9-4b5b-8db4-ec4d77459f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | model               | TimerModel         | 84.0 M | eval \n",
      "1 | classification_head | Sequential         | 657 K  | train\n",
      "2 | loss_function       | CrossEntropyLoss   | 0      | train\n",
      "3 | train_acc           | MulticlassAccuracy | 0      | train\n",
      "4 | val_acc             | MulticlassAccuracy | 0      | train\n",
      "5 | val_f1              | MulticlassF1Score  | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "657 K     Trainable params\n",
      "84.0 M    Non-trainable params\n",
      "84.7 M    Total params\n",
      "338.807   Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "117       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511fa7d22a3149dfb061145a2eb4c37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad6d04da6b14e90843e988ce3c04d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf4d09c9bc84cd08c1418ddddee549d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27ea03dc24843b7bf6ccac578a41ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9164acf543436f88c95188498e5f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc138eedac424ac1bc613c14ec64c6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04064747e541438cbd8abad89e059f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63005fd26b674838bc7499200205b269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9e3b86ab1e47ebb5eeefd20ec5b5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(df, model, len(classes), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656a299-b168-40f9-b640-4c5eea51729c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988b4bb-2f28-4cdc-8843-25329d78552f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a7f12-23d4-43c5-aab2-c9b8127565e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709c184-8b73-4437-bfbd-9a35e8ef3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
