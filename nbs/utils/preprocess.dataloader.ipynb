{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe8adef-d861-4971-9d34-5bed2e376897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp preprocess.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc73e725-bd0c-49b0-8a3f-6b6e64119b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import gc\n",
    "\n",
    "# from torch.serialization import safe_globals\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb915ed2-dc81-4b68-bde7-8e45445be373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.ERROR)  # Change to DEBUG for more details\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914ef341-ee5b-4dae-a904-35841cb292a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58f938c-14c5-4107-bf19-972d879d3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4af791-855c-40b0-9835-992b7b225cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TSRegressionDataset(Dataset):\n",
    "    def __init__(self, df, in_features, out_features, window=1):\n",
    "        super(TSRegressionDataset, self).__init__()\n",
    "\n",
    "        self.data = df\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.window = window\n",
    "\n",
    "        self.groups = {uid: group.reset_index(drop=True) for uid, group in df.groupby(\"unique_id\")}\n",
    "\n",
    "    def __len__(self):\n",
    "        assert self.in_features + self.out_features < len(\n",
    "            self.data\n",
    "        ), f\"in_features + out_features should not be greater than series len {self.data.shape[0]}\"\n",
    "\n",
    "        return sum(\n",
    "            [\n",
    "                (len(g) - (self.in_features + self.out_features)) // self.window + 1\n",
    "                for g in self.groups.values()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        for uid, df in self.groups.items():\n",
    "            max_idx = (len(df) - (self.in_features + self.out_features)) // self.window + 1\n",
    "\n",
    "            if idx < max_idx:\n",
    "                start = idx * self.window\n",
    "                x = torch.tensor(\n",
    "                    df[\"y\"].iloc[start : start + self.in_features].values,\n",
    "                    dtype=torch.float32,  # device=torch.device(\"cuda\")\n",
    "                )\n",
    "                y = torch.tensor(\n",
    "                    df[\"y\"]\n",
    "                    .iloc[start + self.in_features : start + self.in_features + self.out_features]\n",
    "                    .values,\n",
    "                    dtype=torch.float32,  # device=torch.device(\"cuda\")\n",
    "                )\n",
    "                return x, y\n",
    "\n",
    "            idx -= max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0712d0-9318-454a-89b8-ba2c0f4b957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TSDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self, df, in_features, out_features, window=1, batch_size=32):\n",
    "        super(TSDataLoader, self).__init__()\n",
    "        self.data = df\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.window = window\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        assert list(self.data.columns) == [\n",
    "            \"unique_id\",\n",
    "            \"ds\",\n",
    "            \"y\",\n",
    "        ], \"Columns must be ['unique_id', 'ds', 'y']\"\n",
    "\n",
    "        self.data = self.data.sort_values([\"unique_id\", \"ds\"])\n",
    "\n",
    "        # Train / Val / Test Split (70/15/15)\n",
    "        train_sz = int(len(self.data) * 0.7)\n",
    "        val_sz = int(len(self.data) * 0.15)\n",
    "\n",
    "        self.train_df = self.data.iloc[:train_sz]\n",
    "        self.val_df = self.data.iloc[train_sz : train_sz + val_sz]\n",
    "        self.test_df = self.data.iloc[train_sz + val_sz :]\n",
    "\n",
    "        self.train = TSRegressionDataset(\n",
    "            self.train_df, self.in_features, self.out_features, self.window\n",
    "        )\n",
    "        self.val = TSRegressionDataset(\n",
    "            self.val_df, self.in_features, self.out_features, self.window\n",
    "        )\n",
    "        self.test = TSRegressionDataset(\n",
    "            self.test_df, self.in_features, self.out_features, self.window\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=32,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=32,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=32,\n",
    "            persistent_workers=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6f31bd-3f43-4c3e-b758-a01bd4336713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12]) torch.Size([32, 6])\n",
      "torch.Size([32, 12]) torch.Size([32, 6])\n",
      "torch.Size([19, 12]) torch.Size([19, 6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from neuralforecast.utils import AirPassengersDF as df\n",
    "\n",
    "    in_features, out_features, window, batch_sz = 12, 6, 1, 32\n",
    "    ds = TSDataLoader(df, in_features, out_features, window, batch_sz)\n",
    "    ds.setup()\n",
    "    for features, labels in ds.train_dataloader():\n",
    "        print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1c9d456-7507-4b08-871c-93bab890416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import gc\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TSPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        input_size,\n",
    "        horizon,\n",
    "        target_col=\"y\",\n",
    "        train_split=0.7,\n",
    "        val_split=0.15,\n",
    "        normalize=True,\n",
    "        scaler_type=\"minmax\",\n",
    "        split_type=\"horizontal\",\n",
    "        step_size=1,\n",
    "        cache_dir=\".\",\n",
    "        use_cache=True,\n",
    "        persist_scaler=False,\n",
    "        experiment_name=\"default_experiment\",\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        logger.info(\"Initializing TSPreprocessor\")\n",
    "        self.df = df\n",
    "        self.input_size = input_size\n",
    "        self.horizon = horizon\n",
    "        self.target_col = target_col\n",
    "        self.train_split = train_split\n",
    "        self.val_split = val_split\n",
    "        self.normalize = normalize\n",
    "        self.scaler_type = scaler_type\n",
    "        self.split_type = split_type\n",
    "        self.step_size = step_size\n",
    "        self.cache_dir = Path(cache_dir) / experiment_name\n",
    "        self.cache_dir.mkdir(exist_ok=True, parents=True)\n",
    "        self.use_cache = use_cache\n",
    "        self.persist_scaler = persist_scaler\n",
    "        self.num_workers = num_workers\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        self.scaler_dir = self.cache_dir / \"scalers\"\n",
    "        self.scaler_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        if not 0 < train_split + val_split <= 1:\n",
    "            raise ValueError(\"train_split + val_split must be between 0 and 1\")\n",
    "        if step_size < 1:\n",
    "            raise ValueError(\"step_size must be >= 1\")\n",
    "\n",
    "        self.train_windows, self.val_windows, self.test_windows = self._process_data()\n",
    "\n",
    "    def _generate_windows(self, series):\n",
    "        series_len = len(series)\n",
    "        if series_len < self.input_size + self.horizon:\n",
    "\n",
    "            return []\n",
    "\n",
    "        max_idx = series_len - self.input_size - self.horizon + 1\n",
    "        if max_idx <= 0:\n",
    "            return []\n",
    "\n",
    "        window_starts = np.arange(0, max_idx, self.step_size, dtype=np.int32)\n",
    "        window_ends = window_starts + self.input_size\n",
    "        horizon_ends = window_ends + self.horizon\n",
    "\n",
    "        valid_windows = horizon_ends <= series_len\n",
    "        window_starts = window_starts[valid_windows]\n",
    "        window_ends = window_ends[valid_windows]\n",
    "        horizon_ends = horizon_ends[valid_windows]\n",
    "\n",
    "        x_windows = np.lib.stride_tricks.sliding_window_view(series, window_shape=self.input_size)[\n",
    "            window_starts\n",
    "        ]\n",
    "\n",
    "        y_windows = np.stack(\n",
    "            [\n",
    "                series[window_end:horizon_end]\n",
    "                for window_end, horizon_end in zip(window_ends, horizon_ends)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return list(zip(x_windows, y_windows))\n",
    "\n",
    "    def _process_one_series(self, unique_id_group):\n",
    "        unique_id, group = unique_id_group\n",
    "        series = group[self.target_col].values.astype(np.float32)\n",
    "\n",
    "        if self.normalize:\n",
    "            scaler_file = self.scaler_dir / f\"{unique_id}_scaler.pkl\"\n",
    "            if self.persist_scaler and scaler_file.exists():\n",
    "                with open(scaler_file, \"rb\") as f:\n",
    "                    scaler = pickle.load(f)\n",
    "                series = scaler.transform(series.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                scaler = MinMaxScaler() if self.scaler_type == \"minmax\" else StandardScaler()\n",
    "                series = scaler.fit_transform(series.reshape(-1, 1)).flatten()\n",
    "                if self.persist_scaler:\n",
    "                    with open(scaler_file, \"wb\") as f:\n",
    "                        pickle.dump(scaler, f)\n",
    "\n",
    "        windows = self._generate_windows(series)\n",
    "        if not windows:\n",
    "            logger.warning(f\"[{unique_id}] Series too short to generate any windows\")\n",
    "            return [], [], [], unique_id\n",
    "\n",
    "        if self.split_type == \"horizontal\":\n",
    "            num_windows = len(windows)\n",
    "            train_end = int(num_windows * self.train_split)\n",
    "            val_end = train_end + int(num_windows * self.val_split)\n",
    "            return (windows[:train_end], windows[train_end:val_end], windows[val_end:], unique_id)\n",
    "        else:  # Vertical split\n",
    "            return windows, _, _, unique_id\n",
    "\n",
    "    def _process_data(self):\n",
    "        logger.info(\"Processing data for all unique_ids\")\n",
    "        cache_file = self.cache_dir / \"preprocessed_windows.pt\"\n",
    "\n",
    "        if self.use_cache and cache_file.exists():\n",
    "            logger.info(\"Loading preprocessed windows from cache\")\n",
    "            with open(cache_file, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            return data[\"train_windows\"], data[\"val_windows\"], data[\"test_windows\"]\n",
    "\n",
    "        grouped = list(self.df.groupby(\"unique_id\"))\n",
    "        train_windows, val_windows, test_windows = [], [], []\n",
    "\n",
    "        if self.split_type == \"vertical\":\n",
    "            logger.info(\"Applying vertical split\")\n",
    "            unique_ids = list(self.df[\"unique_id\"].unique())\n",
    "            np.random.shuffle(unique_ids)\n",
    "            total_series = len(unique_ids)\n",
    "            train_end = int(total_series * self.train_split)\n",
    "            val_end = train_end + int(total_series * self.val_split)\n",
    "\n",
    "            train_ids = unique_ids[:train_end]\n",
    "            val_ids = unique_ids[train_end:val_end]\n",
    "            test_ids = unique_ids[val_end:]\n",
    "            # print(\"val_ids\",val_ids,\"test_ids\",test_ids)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    executor.map(self._process_one_series, grouped),\n",
    "                    total=len(grouped),\n",
    "                    desc=\"Processing series\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for train_w, val_w, test_w, unique_id in results:\n",
    "            if self.split_type == \"horizontal\":\n",
    "                train_windows.extend(train_w)\n",
    "                val_windows.extend(val_w)\n",
    "                test_windows.extend(test_w)\n",
    "            else:  # Vertical split\n",
    "\n",
    "                if unique_id in train_ids:\n",
    "                    train_windows.extend(train_w)\n",
    "                elif unique_id in val_ids:\n",
    "                    val_windows.extend(train_w)\n",
    "                elif unique_id in test_ids:\n",
    "                    test_windows.extend(train_w)\n",
    "\n",
    "        if self.use_cache:\n",
    "            logger.info(\"Saving preprocessed windows to cache\")\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        \"train_windows\": train_windows,\n",
    "                        \"val_windows\": val_windows,\n",
    "                        \"test_windows\": test_windows,\n",
    "                    },\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Train windows: {len(train_windows)}, Val windows: {len(val_windows)}, Test windows: {len(test_windows)}\"\n",
    "        )\n",
    "        del self.df\n",
    "        return train_windows, val_windows, test_windows\n",
    "\n",
    "    def inverse_transform(self, data, unique_id):\n",
    "        logger.info(f\"Inverse transforming data for unique_id: {unique_id}\")\n",
    "        scaler_file = self.scaler_dir / f\"{unique_id}_scaler.pkl\"\n",
    "        if scaler_file.exists():\n",
    "            with open(scaler_file, \"rb\") as f:\n",
    "                scaler = pickle.load(f)\n",
    "            return scaler.inverse_transform(data.reshape(-1, 1)).flatten()\n",
    "        logger.warning(f\"Scaler for {unique_id} not found. Returning original data.\")\n",
    "        return data\n",
    "\n",
    "    def pre_prediction_transform(self, series: np.ndarray, unique_id: str) -> np.ndarray:\n",
    "        scaler_file = self.scaler_dir / f\"{unique_id}_scaler.pkl\"\n",
    "        if scaler_file.exists():\n",
    "            with open(scaler_file, \"rb\") as f:\n",
    "                scaler = pickle.load(f)\n",
    "            return scaler.transform(series.reshape(-1, 1)).flatten()\n",
    "        logger.warning(f\"Scaler for {unique_id} not found. Returning original series.\")\n",
    "        return series\n",
    "\n",
    "    def post_prediction_transform(self, prediction: np.ndarray, unique_id: str) -> np.ndarray:\n",
    "        return self.inverse_transform(prediction, unique_id)\n",
    "\n",
    "\n",
    "class UnivariateTSDataset(Dataset):\n",
    "    def __init__(self, windows, device: str = None):\n",
    "        logger.info(\"Initializing UnivariateTSDataset\")\n",
    "        self.x = np.stack([w[0] for w in windows], axis=0).astype(np.float32)\n",
    "        self.y = np.stack([w[1] for w in windows], axis=0).astype(np.float32)\n",
    "\n",
    "        self.device = device\n",
    "        if device:\n",
    "            logger.info(\"Preloading tensors to device: %s\", device)\n",
    "            self.x_tensor = torch.from_numpy(self.x).to(device)\n",
    "            self.y_tensor = torch.from_numpy(self.y).to(device)\n",
    "        else:\n",
    "            self.x_tensor = self.y_tensor = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.device:\n",
    "            return self.x_tensor[idx], self.y_tensor[idx]\n",
    "        else:\n",
    "            return torch.from_numpy(self.x[idx]), torch.from_numpy(self.y[idx])\n",
    "\n",
    "\n",
    "class UnivariateTSDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprocessor: TSPreprocessor,\n",
    "        batch_size=32,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "        gpu_preload=False,\n",
    "        experiment_name=\"default_experiment\",\n",
    "    ):\n",
    "        logger.info(\"Initializing UnivariateTSDataModule\")\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"preprocessor\"])\n",
    "        self.preprocessor = preprocessor\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = min(num_workers, torch.get_num_threads())\n",
    "        self.pin_memory = pin_memory\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "        self.persistent_workers = persistent_workers\n",
    "        self.gpu_preload = gpu_preload\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "    def setup(self, stage: str = None):\n",
    "        logger.info(f\"Setting up datamodule for stage: {stage}\")\n",
    "        if stage in (\"fit\", None):\n",
    "            self.train_dataset = UnivariateTSDataset(\n",
    "                self.preprocessor.train_windows, device=self.device if self.gpu_preload else None\n",
    "            )\n",
    "            self.val_dataset = UnivariateTSDataset(\n",
    "                self.preprocessor.val_windows, device=self.device if self.gpu_preload else None\n",
    "            )\n",
    "        if stage in (\"validate\", None):\n",
    "            self.val_dataset = UnivariateTSDataset(\n",
    "                self.preprocessor.val_windows, device=self.device if self.gpu_preload else None\n",
    "            )\n",
    "        if stage in (\"test\", None):\n",
    "            self.test_dataset = UnivariateTSDataset(\n",
    "                self.preprocessor.test_windows, device=self.device if self.gpu_preload else None\n",
    "            )\n",
    "\n",
    "    def _create_dataloader(self, dataset, shuffle=False):\n",
    "        logger.info(\"Creating dataloader\")\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory and not self.gpu_preload,\n",
    "            prefetch_factor=self.prefetch_factor,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "            drop_last=shuffle,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        logger.info(\"Getting train dataloader\")\n",
    "        return self._create_dataloader(self.train_dataset, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        logger.info(\"Getting val dataloader\")\n",
    "        return self._create_dataloader(self.val_dataset)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        logger.info(\"Getting test dataloader\")\n",
    "        return self._create_dataloader(self.test_dataset)\n",
    "\n",
    "    def inverse_transform(self, data, unique_id):\n",
    "        return self.preprocessor.inverse_transform(data, unique_id)\n",
    "\n",
    "    def pre_prediction_transform(self, series: np.ndarray, unique_id: str) -> np.ndarray:\n",
    "        return self.preprocessor.pre_prediction_transform(series, unique_id)\n",
    "\n",
    "    def post_prediction_transform(self, prediction: np.ndarray, unique_id: str) -> np.ndarray:\n",
    "        return self.preprocessor.post_prediction_transform(prediction, unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f802e1a-b6c4-434f-a874-dab5db19cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav-pc/projects/ts/.venv/lib/python3.12/site-packages/datasetsforecast/m3.py:108: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(class_group.freq)\n",
      "WARNING:__main__:[M1] Series too short to generate any windows\n",
      "WARNING:__main__:[M100] Series too short to generate any windows\n",
      "Processing series:   0%|                                                                                                        | 0/1428 [00:00<?, ?it/s]WARNING:__main__:[M10] Series too short to generate any windows\n",
      "WARNING:__main__:[M101] Series too short to generate any windows\n",
      "WARNING:__main__:[M102] Series too short to generate any windows\n",
      "WARNING:__main__:[M103] Series too short to generate any windows\n",
      "WARNING:__main__:[M104] Series too short to generate any windows\n",
      "WARNING:__main__:[M105] Series too short to generate any windows\n",
      "WARNING:__main__:[M106] Series too short to generate any windows\n",
      "WARNING:__main__:[M107] Series too short to generate any windows\n",
      "WARNING:__main__:[M1079] Series too short to generate any windows\n",
      "WARNING:__main__:[M108] Series too short to generate any windows\n",
      "WARNING:__main__:[M1078] Series too short to generate any windows\n",
      "WARNING:__main__:[M109] Series too short to generate any windows\n",
      "WARNING:__main__:[M11] Series too short to generate any windows\n",
      "WARNING:__main__:[M110] Series too short to generate any windows\n",
      "WARNING:__main__:[M1105] Series too short to generate any windows\n",
      "WARNING:__main__:[M111] Series too short to generate any windows\n",
      "WARNING:__main__:[M112] Series too short to generate any windows\n",
      "WARNING:__main__:[M113] Series too short to generate any windows\n",
      "WARNING:__main__:[M114] Series too short to generate any windows\n",
      "WARNING:__main__:[M115] Series too short to generate any windows\n",
      "WARNING:__main__:[M116] Series too short to generate any windows\n",
      "WARNING:__main__:[M117] Series too short to generate any windows\n",
      "WARNING:__main__:[M118] Series too short to generate any windows\n",
      "WARNING:__main__:[M119] Series too short to generate any windows\n",
      "WARNING:__main__:[M12] Series too short to generate any windows\n",
      "WARNING:__main__:[M120] Series too short to generate any windows\n",
      "WARNING:__main__:[M121] Series too short to generate any windows\n",
      "WARNING:__main__:[M122] Series too short to generate any windows\n",
      "Processing series:  17%|███████████████▍                                                                            | 239/1428 [00:00<00:00, 2300.91it/s]WARNING:__main__:[M123] Series too short to generate any windows\n",
      "WARNING:__main__:[M124] Series too short to generate any windows\n",
      "WARNING:__main__:[M125] Series too short to generate any windows\n",
      "WARNING:__main__:[M1255] Series too short to generate any windows\n",
      "WARNING:__main__:[M126] Series too short to generate any windows\n",
      "WARNING:__main__:[M1260] Series too short to generate any windows\n",
      "WARNING:__main__:[M1261] Series too short to generate any windows\n",
      "WARNING:__main__:[M1262] Series too short to generate any windows\n",
      "WARNING:__main__:[M1263] Series too short to generate any windows\n",
      "WARNING:__main__:[M1264] Series too short to generate any windows\n",
      "WARNING:__main__:[M1265] Series too short to generate any windows\n",
      "WARNING:__main__:[M127] Series too short to generate any windows\n",
      "WARNING:__main__:[M128] Series too short to generate any windows\n",
      "WARNING:__main__:[M129] Series too short to generate any windows\n",
      "WARNING:__main__:[M13] Series too short to generate any windows\n",
      "WARNING:__main__:[M130] Series too short to generate any windows\n",
      "WARNING:__main__:[M131] Series too short to generate any windows\n",
      "WARNING:__main__:[M132] Series too short to generate any windows\n",
      "WARNING:__main__:[M133] Series too short to generate any windows\n",
      "WARNING:__main__:[M134] Series too short to generate any windows\n",
      "WARNING:__main__:[M1348] Series too short to generate any windows\n",
      "WARNING:__main__:[M1349] Series too short to generate any windows\n",
      "WARNING:__main__:[M1350] Series too short to generate any windows\n",
      "WARNING:__main__:[M135] Series too short to generate any windows\n",
      "WARNING:__main__:[M1351] Series too short to generate any windows\n",
      "WARNING:__main__:[M136] Series too short to generate any windows\n",
      "WARNING:__main__:[M137] Series too short to generate any windows\n",
      "WARNING:__main__:[M138] Series too short to generate any windows\n",
      "WARNING:__main__:[M139] Series too short to generate any windows\n",
      "WARNING:__main__:[M14] Series too short to generate any windows\n",
      "WARNING:__main__:[M140] Series too short to generate any windows\n",
      "WARNING:__main__:[M1400] Series too short to generate any windows\n",
      "WARNING:__main__:[M1402] Series too short to generate any windows\n",
      "WARNING:__main__:[M1401] Series too short to generate any windows\n",
      "WARNING:__main__:[M1403] Series too short to generate any windows\n",
      "WARNING:__main__:[M1404] Series too short to generate any windows\n",
      "WARNING:__main__:[M1406] Series too short to generate any windows\n",
      "WARNING:__main__:[M1405] Series too short to generate any windows\n",
      "WARNING:__main__:[M1407] Series too short to generate any windows\n",
      "WARNING:__main__:[M1408] Series too short to generate any windows\n",
      "WARNING:__main__:[M1409] Series too short to generate any windows\n",
      "WARNING:__main__:[M141] Series too short to generate any windows\n",
      "WARNING:__main__:[M1410] Series too short to generate any windows\n",
      "WARNING:__main__:[M1411] Series too short to generate any windows\n",
      "WARNING:__main__:[M1412] Series too short to generate any windows\n",
      "WARNING:__main__:[M1413] Series too short to generate any windows\n",
      "WARNING:__main__:[M1414] Series too short to generate any windows\n",
      "WARNING:__main__:[M1415] Series too short to generate any windows\n",
      "WARNING:__main__:[M1416] Series too short to generate any windows\n",
      "WARNING:__main__:[M1417] Series too short to generate any windows\n",
      "WARNING:__main__:[M1418] Series too short to generate any windows\n",
      "WARNING:__main__:[M1419] Series too short to generate any windows\n",
      "WARNING:__main__:[M1420] Series too short to generate any windows\n",
      "WARNING:__main__:[M142] Series too short to generate any windows\n",
      "WARNING:__main__:[M1421] Series too short to generate any windows\n",
      "WARNING:__main__:[M1422] Series too short to generate any windows\n",
      "WARNING:__main__:[M1423] Series too short to generate any windows\n",
      "WARNING:__main__:[M1424] Series too short to generate any windows\n",
      "WARNING:__main__:[M1425] Series too short to generate any windows\n",
      "WARNING:__main__:[M1426] Series too short to generate any windows\n",
      "WARNING:__main__:[M1427] Series too short to generate any windows\n",
      "WARNING:__main__:[M1428] Series too short to generate any windows\n",
      "WARNING:__main__:[M143] Series too short to generate any windows\n",
      "WARNING:__main__:[M144] Series too short to generate any windows\n",
      "WARNING:__main__:[M145] Series too short to generate any windows\n",
      "WARNING:__main__:[M147] Series too short to generate any windows\n",
      "WARNING:__main__:[M146] Series too short to generate any windows\n",
      "WARNING:__main__:[M148] Series too short to generate any windows\n",
      "WARNING:__main__:[M149] Series too short to generate any windows\n",
      "WARNING:__main__:[M15] Series too short to generate any windows\n",
      "WARNING:__main__:[M151] Series too short to generate any windows\n",
      "WARNING:__main__:[M150] Series too short to generate any windows\n",
      "WARNING:__main__:[M152] Series too short to generate any windows\n",
      "WARNING:__main__:[M153] Series too short to generate any windows\n",
      "WARNING:__main__:[M154] Series too short to generate any windows\n",
      "WARNING:__main__:[M155] Series too short to generate any windows\n",
      "WARNING:__main__:[M156] Series too short to generate any windows\n",
      "WARNING:__main__:[M157] Series too short to generate any windows\n",
      "WARNING:__main__:[M158] Series too short to generate any windows\n",
      "WARNING:__main__:[M159] Series too short to generate any windows\n",
      "WARNING:__main__:[M16] Series too short to generate any windows\n",
      "WARNING:__main__:[M160] Series too short to generate any windows\n",
      "WARNING:__main__:[M161] Series too short to generate any windows\n",
      "WARNING:__main__:[M162] Series too short to generate any windows\n",
      "WARNING:__main__:[M164] Series too short to generate any windows\n",
      "WARNING:__main__:[M163] Series too short to generate any windows\n",
      "WARNING:__main__:[M165] Series too short to generate any windows\n",
      "WARNING:__main__:[M166] Series too short to generate any windows\n",
      "WARNING:__main__:[M167] Series too short to generate any windows\n",
      "WARNING:__main__:[M168] Series too short to generate any windows\n",
      "WARNING:__main__:[M169] Series too short to generate any windows\n",
      "WARNING:__main__:[M17] Series too short to generate any windows\n",
      "WARNING:__main__:[M171] Series too short to generate any windows\n",
      "WARNING:__main__:[M170] Series too short to generate any windows\n",
      "WARNING:__main__:[M173] Series too short to generate any windows\n",
      "WARNING:__main__:[M172] Series too short to generate any windows\n",
      "WARNING:__main__:[M174] Series too short to generate any windows\n",
      "WARNING:__main__:[M175] Series too short to generate any windows\n",
      "WARNING:__main__:[M176] Series too short to generate any windows\n",
      "WARNING:__main__:[M177] Series too short to generate any windows\n",
      "WARNING:__main__:[M178] Series too short to generate any windows\n",
      "WARNING:__main__:[M179] Series too short to generate any windows\n",
      "WARNING:__main__:[M18] Series too short to generate any windows\n",
      "WARNING:__main__:[M180] Series too short to generate any windows\n",
      "WARNING:__main__:[M181] Series too short to generate any windows\n",
      "WARNING:__main__:[M182] Series too short to generate any windows\n",
      "WARNING:__main__:[M184] Series too short to generate any windows\n",
      "WARNING:__main__:[M186] Series too short to generate any windows\n",
      "WARNING:__main__:[M183] Series too short to generate any windows\n",
      "WARNING:__main__:[M185] Series too short to generate any windows\n",
      "Processing series:  37%|█████████████████████████████████▋                                                          | 523/1428 [00:00<00:00, 2607.89it/s]WARNING:__main__:[M187] Series too short to generate any windows\n",
      "WARNING:__main__:[M188] Series too short to generate any windows\n",
      "WARNING:__main__:[M189] Series too short to generate any windows\n",
      "WARNING:__main__:[M19] Series too short to generate any windows\n",
      "WARNING:__main__:[M190] Series too short to generate any windows\n",
      "WARNING:__main__:[M191] Series too short to generate any windows\n",
      "WARNING:__main__:[M192] Series too short to generate any windows\n",
      "WARNING:__main__:[M194] Series too short to generate any windows\n",
      "WARNING:__main__:[M195] Series too short to generate any windows\n",
      "WARNING:__main__:[M193] Series too short to generate any windows\n",
      "WARNING:__main__:[M196] Series too short to generate any windows\n",
      "WARNING:__main__:[M197] Series too short to generate any windows\n",
      "WARNING:__main__:[M198] Series too short to generate any windows\n",
      "WARNING:__main__:[M199] Series too short to generate any windows\n",
      "WARNING:__main__:[M2] Series too short to generate any windows\n",
      "WARNING:__main__:[M20] Series too short to generate any windows\n",
      "WARNING:__main__:[M200] Series too short to generate any windows\n",
      "WARNING:__main__:[M201] Series too short to generate any windows\n",
      "WARNING:__main__:[M202] Series too short to generate any windows\n",
      "WARNING:__main__:[M203] Series too short to generate any windows\n",
      "WARNING:__main__:[M204] Series too short to generate any windows\n",
      "WARNING:__main__:[M205] Series too short to generate any windows\n",
      "WARNING:__main__:[M206] Series too short to generate any windows\n",
      "WARNING:__main__:[M207] Series too short to generate any windows\n",
      "WARNING:__main__:[M208] Series too short to generate any windows\n",
      "WARNING:__main__:[M21] Series too short to generate any windows\n",
      "WARNING:__main__:[M209] Series too short to generate any windows\n",
      "WARNING:__main__:[M210] Series too short to generate any windows\n",
      "WARNING:__main__:[M211] Series too short to generate any windows\n",
      "WARNING:__main__:[M213] Series too short to generate any windows\n",
      "WARNING:__main__:[M212] Series too short to generate any windows\n",
      "WARNING:__main__:[M215] Series too short to generate any windows\n",
      "WARNING:__main__:[M214] Series too short to generate any windows\n",
      "WARNING:__main__:[M216] Series too short to generate any windows\n",
      "WARNING:__main__:[M217] Series too short to generate any windows\n",
      "WARNING:__main__:[M218] Series too short to generate any windows\n",
      "WARNING:__main__:[M219] Series too short to generate any windows\n",
      "WARNING:__main__:[M22] Series too short to generate any windows\n",
      "WARNING:__main__:[M220] Series too short to generate any windows\n",
      "WARNING:__main__:[M222] Series too short to generate any windows\n",
      "WARNING:__main__:[M221] Series too short to generate any windows\n",
      "WARNING:__main__:[M223] Series too short to generate any windows\n",
      "WARNING:__main__:[M224] Series too short to generate any windows\n",
      "WARNING:__main__:[M225] Series too short to generate any windows\n",
      "WARNING:__main__:[M226] Series too short to generate any windows\n",
      "WARNING:__main__:[M227] Series too short to generate any windows\n",
      "WARNING:__main__:[M228] Series too short to generate any windows\n",
      "WARNING:__main__:[M229] Series too short to generate any windows\n",
      "WARNING:__main__:[M23] Series too short to generate any windows\n",
      "WARNING:__main__:[M230] Series too short to generate any windows\n",
      "WARNING:__main__:[M231] Series too short to generate any windows\n",
      "WARNING:__main__:[M232] Series too short to generate any windows\n",
      "WARNING:__main__:[M233] Series too short to generate any windows\n",
      "WARNING:__main__:[M234] Series too short to generate any windows\n",
      "WARNING:__main__:[M235] Series too short to generate any windows\n",
      "WARNING:__main__:[M237] Series too short to generate any windows\n",
      "WARNING:__main__:[M236] Series too short to generate any windows\n",
      "WARNING:__main__:[M238] Series too short to generate any windows\n",
      "WARNING:__main__:[M239] Series too short to generate any windows\n",
      "WARNING:__main__:[M24] Series too short to generate any windows\n",
      "WARNING:__main__:[M240] Series too short to generate any windows\n",
      "WARNING:__main__:[M241] Series too short to generate any windows\n",
      "WARNING:__main__:[M242] Series too short to generate any windows\n",
      "WARNING:__main__:[M243] Series too short to generate any windows\n",
      "WARNING:__main__:[M244] Series too short to generate any windows\n",
      "WARNING:__main__:[M245] Series too short to generate any windows\n",
      "WARNING:__main__:[M246] Series too short to generate any windows\n",
      "WARNING:__main__:[M247] Series too short to generate any windows\n",
      "WARNING:__main__:[M248] Series too short to generate any windows\n",
      "WARNING:__main__:[M249] Series too short to generate any windows\n",
      "WARNING:__main__:[M25] Series too short to generate any windows\n",
      "WARNING:__main__:[M250] Series too short to generate any windows\n",
      "WARNING:__main__:[M251] Series too short to generate any windows\n",
      "WARNING:__main__:[M252] Series too short to generate any windows\n",
      "WARNING:__main__:[M253] Series too short to generate any windows\n",
      "WARNING:__main__:[M255] Series too short to generate any windows\n",
      "WARNING:__main__:[M254] Series too short to generate any windows\n",
      "WARNING:__main__:[M256] Series too short to generate any windows\n",
      "WARNING:__main__:[M258] Series too short to generate any windows\n",
      "WARNING:__main__:[M257] Series too short to generate any windows\n",
      "WARNING:__main__:[M259] Series too short to generate any windows\n",
      "WARNING:__main__:[M26] Series too short to generate any windows\n",
      "WARNING:__main__:[M260] Series too short to generate any windows\n",
      "WARNING:__main__:[M261] Series too short to generate any windows\n",
      "WARNING:__main__:[M262] Series too short to generate any windows\n",
      "WARNING:__main__:[M263] Series too short to generate any windows\n",
      "WARNING:__main__:[M264] Series too short to generate any windows\n",
      "WARNING:__main__:[M265] Series too short to generate any windows\n",
      "WARNING:__main__:[M266] Series too short to generate any windows\n",
      "WARNING:__main__:[M267] Series too short to generate any windows\n",
      "WARNING:__main__:[M268] Series too short to generate any windows\n",
      "WARNING:__main__:[M269] Series too short to generate any windows\n",
      "WARNING:__main__:[M27] Series too short to generate any windows\n",
      "WARNING:__main__:[M270] Series too short to generate any windows\n",
      "WARNING:__main__:[M271] Series too short to generate any windows\n",
      "WARNING:__main__:[M272] Series too short to generate any windows\n",
      "WARNING:__main__:[M273] Series too short to generate any windows\n",
      "WARNING:__main__:[M275] Series too short to generate any windows\n",
      "WARNING:__main__:[M274] Series too short to generate any windows\n",
      "WARNING:__main__:[M276] Series too short to generate any windows\n",
      "WARNING:__main__:[M277] Series too short to generate any windows\n",
      "WARNING:__main__:[M28] Series too short to generate any windows\n",
      "WARNING:__main__:[M29] Series too short to generate any windows\n",
      "WARNING:__main__:[M3] Series too short to generate any windows\n",
      "WARNING:__main__:[M30] Series too short to generate any windows\n",
      "WARNING:__main__:[M31] Series too short to generate any windows\n",
      "WARNING:__main__:[M32] Series too short to generate any windows\n",
      "WARNING:__main__:[M33] Series too short to generate any windows\n",
      "WARNING:__main__:[M34] Series too short to generate any windows\n",
      "WARNING:__main__:[M35] Series too short to generate any windows\n",
      "WARNING:__main__:[M36] Series too short to generate any windows\n",
      "WARNING:__main__:[M37] Series too short to generate any windows\n",
      "WARNING:__main__:[M38] Series too short to generate any windows\n",
      "WARNING:__main__:[M39] Series too short to generate any windows\n",
      "WARNING:__main__:[M4] Series too short to generate any windows\n",
      "WARNING:__main__:[M40] Series too short to generate any windows\n",
      "WARNING:__main__:[M41] Series too short to generate any windows\n",
      "WARNING:__main__:[M42] Series too short to generate any windows\n",
      "WARNING:__main__:[M43] Series too short to generate any windows\n",
      "Processing series:  55%|██████████████████████████████████████████████████▌                                         | 785/1428 [00:00<00:00, 2387.95it/s]WARNING:__main__:[M44] Series too short to generate any windows\n",
      "WARNING:__main__:[M45] Series too short to generate any windows\n",
      "WARNING:__main__:[M46] Series too short to generate any windows\n",
      "WARNING:__main__:[M47] Series too short to generate any windows\n",
      "WARNING:__main__:[M48] Series too short to generate any windows\n",
      "WARNING:__main__:[M49] Series too short to generate any windows\n",
      "WARNING:__main__:[M5] Series too short to generate any windows\n",
      "WARNING:__main__:[M50] Series too short to generate any windows\n",
      "WARNING:__main__:[M51] Series too short to generate any windows\n",
      "WARNING:__main__:[M52] Series too short to generate any windows\n",
      "WARNING:__main__:[M53] Series too short to generate any windows\n",
      "WARNING:__main__:[M54] Series too short to generate any windows\n",
      "WARNING:__main__:[M55] Series too short to generate any windows\n",
      "WARNING:__main__:[M56] Series too short to generate any windows\n",
      "WARNING:__main__:[M57] Series too short to generate any windows\n",
      "WARNING:__main__:[M58] Series too short to generate any windows\n",
      "WARNING:__main__:[M59] Series too short to generate any windows\n",
      "WARNING:__main__:[M6] Series too short to generate any windows\n",
      "WARNING:__main__:[M60] Series too short to generate any windows\n",
      "WARNING:__main__:[M61] Series too short to generate any windows\n",
      "WARNING:__main__:[M62] Series too short to generate any windows\n",
      "WARNING:__main__:[M63] Series too short to generate any windows\n",
      "WARNING:__main__:[M64] Series too short to generate any windows\n",
      "WARNING:__main__:[M65] Series too short to generate any windows\n",
      "WARNING:__main__:[M66] Series too short to generate any windows\n",
      "WARNING:__main__:[M67] Series too short to generate any windows\n",
      "Processing series:  74%|███████████████████████████████████████████████████████████████████▏                       | 1054/1428 [00:00<00:00, 2483.18it/s]WARNING:__main__:[M68] Series too short to generate any windows\n",
      "WARNING:__main__:[M69] Series too short to generate any windows\n",
      "WARNING:__main__:[M7] Series too short to generate any windows\n",
      "WARNING:__main__:[M70] Series too short to generate any windows\n",
      "WARNING:__main__:[M71] Series too short to generate any windows\n",
      "WARNING:__main__:[M72] Series too short to generate any windows\n",
      "WARNING:__main__:[M73] Series too short to generate any windows\n",
      "WARNING:__main__:[M74] Series too short to generate any windows\n",
      "WARNING:__main__:[M75] Series too short to generate any windows\n",
      "WARNING:__main__:[M76] Series too short to generate any windows\n",
      "WARNING:__main__:[M77] Series too short to generate any windows\n",
      "WARNING:__main__:[M78] Series too short to generate any windows\n",
      "WARNING:__main__:[M79] Series too short to generate any windows\n",
      "WARNING:__main__:[M8] Series too short to generate any windows\n",
      "WARNING:__main__:[M80] Series too short to generate any windows\n",
      "WARNING:__main__:[M81] Series too short to generate any windows\n",
      "WARNING:__main__:[M82] Series too short to generate any windows\n",
      "WARNING:__main__:[M83] Series too short to generate any windows\n",
      "WARNING:__main__:[M84] Series too short to generate any windows\n",
      "WARNING:__main__:[M85] Series too short to generate any windows\n",
      "WARNING:__main__:[M86] Series too short to generate any windows\n",
      "WARNING:__main__:[M87] Series too short to generate any windows\n",
      "WARNING:__main__:[M88] Series too short to generate any windows\n",
      "WARNING:__main__:[M89] Series too short to generate any windows\n",
      "WARNING:__main__:[M90] Series too short to generate any windows\n",
      "Processing series:  92%|███████████████████████████████████████████████████████████████████████████████████▊       | 1315/1428 [00:00<00:00, 2524.63it/s]WARNING:__main__:[M9] Series too short to generate any windows\n",
      "WARNING:__main__:[M91] Series too short to generate any windows\n",
      "WARNING:__main__:[M92] Series too short to generate any windows\n",
      "WARNING:__main__:[M93] Series too short to generate any windows\n",
      "WARNING:__main__:[M94] Series too short to generate any windows\n",
      "WARNING:__main__:[M95] Series too short to generate any windows\n",
      "WARNING:__main__:[M96] Series too short to generate any windows\n",
      "WARNING:__main__:[M97] Series too short to generate any windows\n",
      "WARNING:__main__:[M98] Series too short to generate any windows\n",
      "WARNING:__main__:[M99] Series too short to generate any windows\n",
      "Processing series: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 1428/1428 [00:00<00:00, 2515.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "## Data loading and preprocessing df.columns - unique_id,ds,y\n",
    "from datasetsforecast.m3 import M3\n",
    "\n",
    "from ts.preprocess.dataloader import TSPreprocessor, UnivariateTSDataModule\n",
    "\n",
    "df = M3().load(\"../data\", group=\"Monthly\")[0]\n",
    "df.sort_values([\"unique_id\", \"ds\"], inplace=True)\n",
    "\n",
    "horizon = 12  # <-- FORECAST HORIZON\n",
    "input_size = horizon * 5\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# from ts.preprocess.dataloader import TSPreprocessor, UnivariateTSDataModule\n",
    "\n",
    "batch_size = 512\n",
    "num_workers = 24\n",
    "step_size = 1\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TSPreprocessor(\n",
    "    df=df,\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    target_col=\"y\",\n",
    "    train_split=0.7,\n",
    "    val_split=0.15,\n",
    "    normalize=True,\n",
    "    scaler_type=\"minmax\",\n",
    "    split_type=\"horizontal\",\n",
    "    step_size=step_size,\n",
    "    cache_dir=\".\",\n",
    "    use_cache=False,\n",
    "    persist_scaler=True,\n",
    "    experiment_name=\"my_experiment\",\n",
    ")\n",
    "# Initialize DataModule\n",
    "ds = UnivariateTSDataModule(\n",
    "    preprocessor=preprocessor,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    "    gpu_preload=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4dc2e3-1fa5-4385-abda-0a588f4d117b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
