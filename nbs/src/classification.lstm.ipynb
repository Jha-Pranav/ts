{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6521f9a-7cbd-4606-8231-db1677d57c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from torch import nn, optim, utils\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f052d3aa-12b5-4756-9bea-e47c8ebfca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/m4_preprocessed.parquet\")\n",
    "lengths = df.no_of_datapoints.values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df.best_model.values)\n",
    "classes = {idx: class_name for idx, class_name in enumerate(le.classes_)}\n",
    "\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(\n",
    "    scaler.fit_transform(df.drop([\"best_model\", \"no_of_datapoints\"], axis=1).T).T,\n",
    "    columns=df.columns[:-2],\n",
    "    index=df.index,\n",
    ").fillna(0.0)\n",
    "sequences = torch.tensor(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c43101-87f4-4804-bd52-ef6d3cfb4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self, sequences, lengths, y, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.sequences = sequences\n",
    "        self.lengths = lengths\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = list(zip(self.sequences, self.lengths, self.y))\n",
    "\n",
    "        # Sort by sequence length (important for packing)\n",
    "        dataset.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        test_size = int(0.2 * len(dataset))\n",
    "        val_size = int(0.1 * len(dataset))\n",
    "        train_size = len(dataset) - test_size - val_size\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "            dataset, [train_size, val_size, test_size]\n",
    "        )\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        sequences, lengths, labels = zip(*batch)\n",
    "\n",
    "        # Convert to tensor\n",
    "        sequences = torch.stack(sequences)\n",
    "        lengths = torch.tensor(lengths)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        return sequences, lengths, labels\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.collate_fn,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39655d9d-9ad5-4483-9189-ec629b50f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dim=128, num_layers=2, num_classes=10, learning_rate=1e-3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=0.3\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # Bidirectional\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.f1_score = torchmetrics.F1Score(\n",
    "            task=\"multiclass\", num_classes=num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x.unsqueeze(-1)\n",
    "        packed_x = pack_padded_sequence(\n",
    "            x.float(), lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, (hn, cn) = self.lstm(packed_x)\n",
    "\n",
    "        hn = torch.cat((hn[-2], hn[-1]), dim=1)  # Bidirectional concat\n",
    "        hn = self.layer_norm(hn)  # Normalize\n",
    "        out = self.fc(hn)\n",
    "        return out\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, lengths, y = batch\n",
    "        y_hat = self.forward(x, lengths)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        return loss, preds, y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, preds, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        f1_score = self.f1_score(preds, y)\n",
    "        self.log_dict(\n",
    "            {\"train_loss\": loss, \"train_accuracy\": accuracy, \"train_f1score\": f1_score},\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, preds, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        f1_score = self.f1_score(preds, y)\n",
    "        self.log_dict(\n",
    "            {\"val_loss\": loss, \"val_accuracy\": accuracy, \"val_f1score\": f1_score}, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, preds, y = self._common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        f1_score = self.f1_score(preds, y)\n",
    "        self.log_dict(\n",
    "            {\"test_loss\": loss, \"test_accuracy\": accuracy, \"test_f1score\": f1_score}, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "\n",
    "    #     # Dynamically calculate total steps based on the Trainer\n",
    "    #     total_steps = self.trainer.estimated_stepping_batches\n",
    "\n",
    "    #     scheduler = {\n",
    "    #         \"scheduler\": optim.lr_scheduler.OneCycleLR(\n",
    "    #             optimizer,\n",
    "    #             max_lr=self.lr,\n",
    "    #             epochs =  1000,\n",
    "    #             steps_per_epoch= 10,\n",
    "    #             # total_steps=1000,  # Ensure proper step count\n",
    "    #             pct_start=0.1,\n",
    "    #             anneal_strategy='cos'\n",
    "    #         ),\n",
    "    #         \"interval\": \"epoch\",  # OneCycleLR updates per step\n",
    "    #     }\n",
    "\n",
    "    #     return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), lr=self.lr, weight_decay=1e-4\n",
    "        )  # AdamW for better generalization\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e07be36f-35f4-4c22-98aa-dce29741782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LSTMDataLoader(sequences, lengths, y, batch_size=778)\n",
    "model = LSTMClassifier(input_dim=1, num_classes=len(set(y)))  # sequences.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "643f32b5-3282-4a44-bbd6-5d23ff65446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at model_checkpoints/lstm_classifier.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm       | LSTM               | 529 K  | train\n",
      "1 | fc         | Linear             | 1.8 K  | train\n",
      "2 | layer_norm | LayerNorm          | 512    | train\n",
      "3 | loss_fn    | CrossEntropyLoss   | 0      | train\n",
      "4 | accuracy   | MulticlassAccuracy | 0      | train\n",
      "5 | f1_score   | MulticlassF1Score  | 0      | train\n",
      "----------------------------------------------------------\n",
      "531 K     Trainable params\n",
      "0         Non-trainable params\n",
      "531 K     Total params\n",
      "2.127     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at model_checkpoints/lstm_classifier.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f649f089b8f4191a1e40b855d4f5d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fafe11f842f4a62882e608e9c18b783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3e82082d944fe8918d7d71b29dce98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b73e4a64dc4f3f9604afb05f3800cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcea3800f494406a4c9d419b498d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6e13a1dfea41bc96d3c4e455f52ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a832945426d4f45b97184eb4d0556e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8533f878e0c345c4b0591a403bf76f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8254bcc60aa4fff85f7bb0b57b17e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca8f31cc4094e549d326b7f6c5a92a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce1be8f9a1b4ce5bd0e2035fdec1e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177014f93f9a470f8416121f13b4332a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c72867ce60d42b4976805100226bed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a20e5ee8f54dab8be00216bd22f50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb14c670b9834eceabf946210cfbc15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbee5dbb2cf4ee39e7792b7737b9d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fbcb47c7064132af09272c61e6eb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae5fffe7b5b45da9098069fcc33aa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"./log/\", name=\"lstm_model_classifier\", version=0.1)\n",
    "\n",
    "\n",
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_f1score\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"lstm-model-classifier-{epoch}-{val_f1score}\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    min_epochs=1,\n",
    "    max_epochs=1000,\n",
    "    # precision='16-mixed',\n",
    "    enable_model_summary=True,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\"val_loss\", patience=15, verbose=False),\n",
    "        checkpoint_callback,\n",
    "    ],\n",
    "    #     default_root_dir=\"mnist_checkpoints/\",\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "ckpt_path = \"model_checkpoints/lstm_classifier.ckpt\"\n",
    "if ckpt_path:\n",
    "    trainer.fit(model, ds, ckpt_path=\"model_checkpoints/lstm_classifier.ckpt\")\n",
    "else:\n",
    "    trainer.fit(model, ds)\n",
    "trainer.save_checkpoint(\"model_checkpoints/lstm_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "542ccb09-17f7-4670-b1fe-b6faacce663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cfe00802304403801dc152f74b6215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36887311935424805    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3460385203361511     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.5230967998504639     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36887311935424805   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3460385203361511    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5230967998504639    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.validate(model, ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e345147-d018-4ed2-9ba5-dce61bb3e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pranav-pc/projects/ts/ts/classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6cce84bc4c4200ae620cfa8a6ef461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3715123236179352     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35136276483535767    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.5156618356704712     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3715123236179352    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35136276483535767   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5156618356704712    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe79c6-b1c0-46c2-a583-333f56450fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632ae2a-7417-423c-b590-105acaa91cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f43acd-b78c-45e4-a569-2ecc767c8e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
