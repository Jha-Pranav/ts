{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9d0f5-0968-439f-a368-61fec72479cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp benchmark.cnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a386a4-07a0-42ed-98f4-b2ca7bf6711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# | export\n",
    "from ts.benchmark.tsdataset import TimeSeriesBenchmarkDataset\n",
    "from ts.classification.cnnclassifer import TimeSeriesDataModule, TSNDTensorClassifier\n",
    "from ts.tsfeatures.ts2image import transform_ts2img_tensor\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820fe45-d1de-46bc-96e6-fae085ec2300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EthanolConcentration',\n",
       " 'FaceDetection',\n",
       " 'Handwriting',\n",
       " 'JapaneseVowels',\n",
       " 'PEMS-SF',\n",
       " 'SelfRegulationSCP1',\n",
       " 'SelfRegulationSCP2',\n",
       " 'SpokenArabicDigits',\n",
       " 'UWaveGestureLibrary']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = TimeSeriesBenchmarkDataset()\n",
    "benchmark.task_datasets[\"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f52787-e655-4aeb-9414-21bd766de62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing >>   EthanolConcentration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming & Saving (X, y): 100%|███████████| 524/524 [01:38<00:00,  5.33it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                        | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | preprocessor     | ChannelReducerAndDownscaler | 1.7 K  | train\n",
      "1 | pretrained_model | EfficientNet                | 4.3 M  | train\n",
      "2 | criterion        | CrossEntropyLoss            | 0      | train\n",
      "3 | accuracy         | MulticlassAccuracy          | 0      | train\n",
      "4 | f1_score         | MulticlassF1Score           | 0      | train\n",
      "5 | auc              | MulticlassAUROC             | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "330 K     Trainable params\n",
      "4.0 M     Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.353    Total estimated model params size (MB)\n",
      "352       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e2654f8efd40aeb4ff5c373b48591b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fb9ca3d47b4b1b9d7b4f55a886b5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "benchmark = TimeSeriesBenchmarkDataset()\n",
    "# ds_list = benchmark.task_datasets[\"classification\"]\n",
    "ds_list = [\n",
    "    \"EthanolConcentration\",\n",
    "    \"FaceDetection\",\n",
    "    \"Handwriting\",\n",
    "    # 'JapaneseVowels',   # Shape missmatch\n",
    "    # 'PEMS-SF',          # cuda out of memorry\n",
    "    \"SelfRegulationSCP1\",\n",
    "    \"SelfRegulationSCP2\",\n",
    "    # 'SpokenArabicDigits',   # Shape missmatch\n",
    "    \"UWaveGestureLibrary\",\n",
    "]\n",
    "\n",
    "for dataset in ds_list:\n",
    "    print(\"Processing >>  \", dataset)\n",
    "    df = benchmark.load_dataset(dataset)\n",
    "    # df = df.sample(min(500, len(df)), replace=False).reset_index(drop=True)\n",
    "\n",
    "    transform_ts2img_tensor(\n",
    "        df, data_dir=f\"{dataset}_classification\", categorical_label=True, label_col=\"label\"\n",
    "    )\n",
    "    del df\n",
    "    gc.collect()  # Force garbage collection\n",
    "\n",
    "    # Load class labels\n",
    "    with open(f\"{dataset}_classification/classes.json\", \"r\") as file:\n",
    "        classes = json.load(file)\n",
    "\n",
    "    # Load a single sample to determine input shape\n",
    "    with torch.no_grad():\n",
    "        x = torch.load(f\"{dataset}_classification/0.pt\")[\"image\"]\n",
    "        input_size = x.shape[-1]\n",
    "        in_channels = x.shape[0]\n",
    "\n",
    "    # Reduce batch size for large sequence lengths\n",
    "    batch_size = 4 if input_size > 550 else 64\n",
    "\n",
    "    ds = TimeSeriesDataModule(\n",
    "        data_dir=f\"{dataset}_classification\",\n",
    "        batch_size=batch_size,\n",
    "        num_workers=6 if batch_size < 8 else 16,  # Optimize workers for memory\n",
    "        #  persistent_workers=False,  # Prevent memory leaks in DataLoader\n",
    "    )\n",
    "    del x\n",
    "    gc.collect()\n",
    "\n",
    "    model = TSNDTensorClassifier(\n",
    "        model_name=\"efficientnet_b0\",\n",
    "        num_classes=len(classes),\n",
    "        in_channels=in_channels,\n",
    "        reduced_channels=3,\n",
    "        input_size=input_size,\n",
    "        output_size=min(255, input_size),\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"benchmark-ts-classification\",\n",
    "        name=f\"cnn.model=efficientnet_b0.ds={dataset}\",\n",
    "    )\n",
    "    wandb_logger.experiment.config.update({\"model\": \"efficientnet_b0\", \"finetune\": False})\n",
    "    wandb_logger.watch(model, log=\"all\")\n",
    "    trainer = pl.Trainer(\n",
    "        logger=wandb_logger,\n",
    "        accelerator=\"auto\",\n",
    "        devices=[0],\n",
    "        min_epochs=1,\n",
    "        max_epochs=2,\n",
    "        enable_checkpointing=True,\n",
    "        precision=\"bf16-mixed\",\n",
    "        callbacks=[pl.callbacks.EarlyStopping(\"val_loss\", patience=5, verbose=False)],\n",
    "    )\n",
    "\n",
    "    ckpt_path = f\"model_checkpoints/{dataset}.ckpt\"\n",
    "\n",
    "    trainer.fit(model, ds)\n",
    "    trainer.save_checkpoint(ckpt_path)\n",
    "    trainer.validate(model, ds)\n",
    "    trainer.test(model, ds)\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    wandb_logger.experiment.unwatch(model)\n",
    "    del model, ds\n",
    "    gc.collect()\n",
    "    # wandb_logger = WandbLogger(log_model=True)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db127f0-9bc9-4dd5-970a-608816f7640f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
