{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02155b56-cdb8-4e29-8681-5cd02690e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp classification.cnnclassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd580ac-2aa4-478e-9b38-63c05f88a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee596a1-f98e-4295-9285-9f8cf6ae0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55e75b-afd3-4169-8831-07efc84a3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TimeSeriesImageDataset(Dataset):\n",
    "    \"\"\"Loads time series image data from .png files and corresponding labels from labels.json.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, resize_shape=(350, 350), transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith(\".png\")]\n",
    "\n",
    "        self.labels = self.load_labels()  # Load labels from labels.json\n",
    "        self.resize_shape = resize_shape\n",
    "        self.transform = transform if transform else self.default_transform()\n",
    "\n",
    "    def load_labels(self):\n",
    "        \"\"\"Loads labels from a single JSON file.\"\"\"\n",
    "        import json\n",
    "\n",
    "        labels_path = os.path.join(self.data_dir, \"labels.json\")\n",
    "        with open(labels_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def default_transform(self):\n",
    "        \"\"\"Returns a default transformation pipeline including resizing.\"\"\"\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(self.resize_shape),\n",
    "                transforms.ToTensor(),  # Converts to [0, 1] float tensor\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to 3-channel RGB\n",
    "\n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.labels[str(idx)], dtype=torch.long)  # Load label from JSON\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cb49f-9c41-48e3-8da8-f5c9beebf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data_dir=\"processed_data\", transform=None):\n",
    "        \"\"\"\n",
    "        PyTorch dataset to load time series transformed into image tensors.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Directory containing the saved .pt files.\n",
    "            transform (callable, optional): Optional transform to apply to images.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".pt\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        sample = torch.load(file_path)\n",
    "\n",
    "        image, label = sample[\"image\"], sample[\"label\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply any transformations (e.g., normalization)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cf916-d30a-40b6-812b-e6bfc59ddf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TimeSeriesDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir=\"processed_data\",\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        val_split=0.1,\n",
    "        test_split=0.1,\n",
    "        resize_shape=(350, 350),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        self.resize_shape = resize_shape\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Randomly split dataset into train, validation, and test sets.\"\"\"\n",
    "        full_dataset = TimeSeriesDataset(self.data_dir)\n",
    "        total_size = len(full_dataset)\n",
    "\n",
    "        val_size = int(self.val_split * total_size)\n",
    "        test_size = int(self.test_split * total_size)\n",
    "        train_size = total_size - val_size - test_size\n",
    "\n",
    "        # ✅ Randomly split dataset\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, val_size, test_size],\n",
    "            generator=torch.Generator().manual_seed(42),  # Ensure reproducibility\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f923e6-795b-4fc8-82cf-ef001a6c55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TSImageClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"convnext_tiny\",\n",
    "        num_classes=10,\n",
    "        hidden_feature=512,\n",
    "        lr=1e-3,\n",
    "        freeze_backbone=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Load model\n",
    "        self.pretrained_model = self._load_model(model_name)\n",
    "\n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in self.pretrained_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Modify classifier for custom classes\n",
    "        self._modify_classifier(hidden_feature, num_classes)\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "        # Metrics (computed per batch)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.f1_score = torchmetrics.F1Score(\n",
    "            task=\"multiclass\", num_classes=num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.auc = torchmetrics.AUROC(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def _load_model(self, model_name):\n",
    "        \"\"\"Load a pretrained model dynamically.\"\"\"\n",
    "        model_dict = {\n",
    "            \"convnext_tiny\": models.convnext_tiny(weights=\"IMAGENET1K_V1\"),\n",
    "            \"efficientnet_b0\": models.efficientnet_b0(weights=\"IMAGENET1K_V1\"),\n",
    "            \"swin_v2_s\": models.swin_v2_s(weights=\"IMAGENET1K_V1\"),\n",
    "            \"resnet50\": models.resnet50(weights=\"IMAGENET1K_V1\"),\n",
    "        }\n",
    "        if model_name not in model_dict:\n",
    "            raise ValueError(\n",
    "                f\"Model '{model_name}' is not supported. Choose from {list(model_dict.keys())}.\"\n",
    "            )\n",
    "        return model_dict[model_name]\n",
    "\n",
    "    def _modify_classifier(self, hidden_feature, num_classes):\n",
    "        \"\"\"Modify classifier head for different models.\"\"\"\n",
    "        if hasattr(self.pretrained_model, \"classifier\"):\n",
    "            in_features = self.pretrained_model.classifier[-1].in_features\n",
    "            self.pretrained_model.classifier[-1] = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden_feature),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                # nn.Linear(hidden_feature, hidden_feature),\n",
    "                # nn.ReLU(),\n",
    "                # nn.Dropout(p=0.3),\n",
    "                nn.Linear(hidden_feature, num_classes),\n",
    "            )\n",
    "        elif hasattr(self.pretrained_model, \"fc\"):\n",
    "            in_features = self.pretrained_model.fc.in_features\n",
    "            self.pretrained_model.fc = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden_feature),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                # nn.Linear(hidden_feature, hidden_feature),\n",
    "                # nn.ReLU(),\n",
    "                # nn.Dropout(p=0.3),\n",
    "                nn.Linear(hidden_feature, num_classes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pretrained_model(x)\n",
    "\n",
    "    def compute_metrics(self, logits, y, prefix):\n",
    "        \"\"\"Compute Accuracy, F1 Score, and AUC for a given batch.\"\"\"\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "        auc = self.auc(logits, y)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                f\"{prefix}_accuracy\": acc,\n",
    "                f\"{prefix}_f1\": f1,\n",
    "                f\"{prefix}_auc\": auc,\n",
    "            },\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"train\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda6cf4-342f-411a-b463-83afa8d15c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36331d-5a91-440e-acb3-19d1fb829bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# Compute dynamic convolution parameters\n",
    "\n",
    "\n",
    "def compute_conv_params(input_size, output_size):\n",
    "    stride = input_size // output_size\n",
    "    kernel_size = (stride * 2) if stride > 1 else 3\n",
    "    padding = (kernel_size - stride) // 2\n",
    "    return kernel_size, stride, padding\n",
    "\n",
    "\n",
    "# Preprocessing: Channel Reduction & Spatial Downsampling\n",
    "\n",
    "\n",
    "class ChannelReducerAndDownscaler(nn.Module):\n",
    "    def __init__(self, in_channels=164, reduced_channels=3, input_size=500, output_size=250):\n",
    "        super(ChannelReducerAndDownscaler, self).__init__()\n",
    "        kernel_size, stride, padding = compute_conv_params(input_size, output_size)\n",
    "\n",
    "        # Reduce Channels\n",
    "        self.channel_reducer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, reduced_channels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Downscale Spatial Dimensions using Conv instead of Linear\n",
    "        self.spatial_downscaler = nn.Conv2d(\n",
    "            reduced_channels, reduced_channels, kernel_size, stride, padding\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_reducer(x)  # Reduce channels\n",
    "        x = self.spatial_downscaler(x)  # Downscale\n",
    "        return x  # Output: (batch, channels, output_size, output_size)\n",
    "\n",
    "\n",
    "# Combined Model: Preprocessing + Classification\n",
    "\n",
    "\n",
    "class TSNDTensorClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"convnext_tiny\",\n",
    "        num_classes=10,\n",
    "        hidden_feature=256,\n",
    "        lr=5e-4,\n",
    "        freeze_backbone=True,\n",
    "        in_channels=164,\n",
    "        reduced_channels=3,\n",
    "        input_size=500,\n",
    "        output_size=250,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Add Preprocessing (Channel Reduction & Downsampling)\n",
    "        self.preprocessor = ChannelReducerAndDownscaler(\n",
    "            in_channels, reduced_channels, input_size, output_size\n",
    "        )\n",
    "\n",
    "        # Load Pretrained Model\n",
    "        self.pretrained_model = self._load_model(model_name)\n",
    "\n",
    "        # Freeze Backbone If Required\n",
    "        if freeze_backbone:\n",
    "            for param in self.pretrained_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Modify Classifier\n",
    "        self._modify_classifier(hidden_feature, num_classes)\n",
    "\n",
    "        # Loss and Metrics\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.f1_score = torchmetrics.F1Score(\n",
    "            task=\"multiclass\", num_classes=num_classes, average=\"macro\"\n",
    "        )\n",
    "        self.auc = torchmetrics.AUROC(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def _load_model(self, model_name):\n",
    "        \"\"\"Load a pretrained model dynamically.\"\"\"\n",
    "        model_dict = {\n",
    "            \"convnext_tiny\": models.convnext_tiny(weights=\"IMAGENET1K_V1\"),\n",
    "            \"efficientnet_b0\": models.efficientnet_b0(weights=\"IMAGENET1K_V1\"),\n",
    "            \"swin_v2_s\": models.swin_v2_s(weights=\"IMAGENET1K_V1\"),\n",
    "            \"resnet50\": models.resnet50(weights=\"IMAGENET1K_V1\"),\n",
    "        }\n",
    "        if model_name not in model_dict:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported model '{model_name}'. Choose from {list(model_dict.keys())}.\"\n",
    "            )\n",
    "        return model_dict[model_name]\n",
    "\n",
    "    def _modify_classifier(self, hidden_feature, num_classes):\n",
    "        \"\"\"Modify classifier head for different models.\"\"\"\n",
    "        if hasattr(self.pretrained_model, \"classifier\"):\n",
    "            in_features = self.pretrained_model.classifier[-1].in_features\n",
    "            self.pretrained_model.classifier[-1] = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden_feature),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(hidden_feature, num_classes),\n",
    "            )\n",
    "        elif hasattr(self.pretrained_model, \"fc\"):\n",
    "            in_features = self.pretrained_model.fc.in_features\n",
    "            self.pretrained_model.fc = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden_feature),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(hidden_feature, num_classes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.preprocessor(x)  # Apply preprocessing first\n",
    "        x = self.pretrained_model(x)  # Pass through classifier\n",
    "        return x\n",
    "\n",
    "    def compute_metrics(self, logits, y, prefix):\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc, f1, auc = self.accuracy(preds, y), self.f1_score(preds, y), self.auc(logits, y)\n",
    "        self.log_dict(\n",
    "            {f\"{prefix}_accuracy\": acc, f\"{prefix}_f1\": f1, f\"{prefix}_auc\": auc}, prog_bar=True\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.compute_metrics(logits, y, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415e8ce-3a2e-4529-a4ce-9a49be6ec48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.rand(8, 145, 700, 700)  # Example Batch: (Batch, Channels, Height, Width)\n",
    "\n",
    "    model = TSNDTensorClassifier(\n",
    "        model_name=\"efficientnet_b0\",\n",
    "        num_classes=5,\n",
    "        in_channels=x.shape[1],\n",
    "        reduced_channels=3,\n",
    "        input_size=x.shape[-1],\n",
    "        output_size=250,\n",
    "    )\n",
    "\n",
    "    output = model(x)\n",
    "    print(output.shape)  # Expected: (Batch, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378158f-a27c-4abf-bdee-88dab85420a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cec2df-28b7-4966-b105-a2f9ebf1ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & preprocess data\n",
    "df = pd.read_parquet(\"data/m4_preprocessed.parquet\")\n",
    "df.sort_values(\"no_of_datapoints\", inplace=True)\n",
    "\n",
    "# Try on smaller dataset\n",
    "df = df[df.no_of_datapoints <= 300]\n",
    "\n",
    "df.drop(columns=[\"no_of_datapoints\"], inplace=True)\n",
    "# ts_series = df.drop([\"best_model\"], axis=1).iloc[20].dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728b1e6-2138-4d19-85dd-8aaab78d1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9925</th>\n",
       "      <th>9926</th>\n",
       "      <th>9927</th>\n",
       "      <th>9928</th>\n",
       "      <th>9929</th>\n",
       "      <th>9930</th>\n",
       "      <th>9931</th>\n",
       "      <th>9932</th>\n",
       "      <th>9933</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1815.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoRegressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1189.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoTheta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1120.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoMFLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3260.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>3490.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoMFLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30218</th>\n",
       "      <td>1498.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30219</th>\n",
       "      <td>3049.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3083.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30220</th>\n",
       "      <td>2470.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30221</th>\n",
       "      <td>6430.0</td>\n",
       "      <td>6340.0</td>\n",
       "      <td>6390.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>6460.0</td>\n",
       "      <td>6520.0</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30223 rows × 9934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1       2       3       4       5       6       7       8       9  \\\n",
       "0      1815.0  1618.0  1598.0  1570.0  1520.0  1600.0  1570.0  1494.0  1367.0   \n",
       "1      1189.0  1225.0  1233.0  1264.0  1445.0  1595.0  1718.0  1668.0  1700.0   \n",
       "2      1120.0  1060.0  1510.0  1630.0  1780.0  1520.0  1530.0  1700.0  1550.0   \n",
       "3      3260.0  2770.0  2890.0  3310.0  3440.0  3700.0  3900.0  3870.0  3490.0   \n",
       "4      2590.0  2510.0  2980.0  2370.0  2220.0  2340.0  2010.0  1960.0  1760.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "30218  1498.0  1503.0  1516.0  1534.0  1536.0  1530.0  1556.0  1565.0  1558.0   \n",
       "30219  3049.0  3056.0  3083.0  3084.0  3100.0  3157.0  3153.0  3162.0  3135.0   \n",
       "30220  2470.0  2390.0  2400.0  2370.0  2390.0  2420.0  2420.0  2390.0  2450.0   \n",
       "30221  6430.0  6340.0  6390.0  6300.0  6360.0  6460.0  6520.0  6480.0  6400.0   \n",
       "30222  1800.0  1790.0  1800.0  1800.0  1810.0  1830.0  1820.0  1810.0  1830.0   \n",
       "\n",
       "           10  ...  9925  9926  9927  9928  9929  9930  9931  9932  9933  \\\n",
       "0      1520.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1      1712.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2      1910.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3      3010.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4      2000.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...       ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "30218  1562.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30219  3093.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30220  2390.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30221  6430.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30222  1830.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "           best_model  \n",
       "0      AutoRegressive  \n",
       "1           AutoTheta  \n",
       "2           AutoMFLES  \n",
       "3                 CES  \n",
       "4           AutoMFLES  \n",
       "...               ...  \n",
       "30218             CES  \n",
       "30219         AutoETS  \n",
       "30220       AutoARIMA  \n",
       "30221             CES  \n",
       "30222             CES  \n",
       "\n",
       "[30223 rows x 9934 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af93a1-1600-4702-9b58-c383ab394bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts.tsfeatures.ts2image import transform_tensor2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc21f8-c274-4506-83cc-2ed237ae6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming & Saving (X, y): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 30223/30223 [03:14<00:00, 155.35it/s]\n"
     ]
    }
   ],
   "source": [
    "transform_tensor2img(\n",
    "    df, data_dir=\"model_classification\", categorical_label=True, label_col=\"best_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87f9ba-bb7c-4dde-a12a-32d1d44ce671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"model_classification/classes.json\", \"r\") as file:\n",
    "    classes = json.load(file)\n",
    "ds = TimeSeriesDataModule(data_dir=\"model_classification\", batch_size=32, num_workers=24)\n",
    "model = TSImageClassifier(\n",
    "    model_name=\"efficientnet_b0\",\n",
    "    num_classes=len(classes),\n",
    "    hidden_feature=512,\n",
    "    lr=3e-3,\n",
    "    freeze_backbone=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfbe6a-48ff-42f9-ab09-63876db7cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"ts-classification\", name=\"cnn.model=efficientnet_b0.ds=model_classifier\"\n",
    ")\n",
    "wandb_logger.experiment.config[\"model\"] = \"efficientnet_b0\"\n",
    "wandb_logger.experiment.config[\"ds\"] = \"model_classifier\"\n",
    "wandb_logger.experiment.config[\"finetune\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e49ef-e799-43e6-813b-226eafb1caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    # logger=wandb_logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    min_epochs=1,\n",
    "    max_epochs=100,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\"val_loss\", patience=5, verbose=False),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590684a-c4cf-400c-8b0f-5e4208152628",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"model_checkpoints/cnn_model_classification.ckpt\"\n",
    "finetune = False\n",
    "if finetune:\n",
    "    trainer.fit(model, ds, ckpt_path=ckpt_path)\n",
    "else:\n",
    "    trainer.fit(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba6dab-a579-4d8a-8074-8d97bd4abd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"model_checkpoints/cnn_model_classification.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdfdbd-35b9-4952-90b4-a1d6139d6af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71ed5277f734e9c9b64625580df6709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22667108476161957    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_auc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48773670196533203    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05385681614279747    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.896951675415039     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22667108476161957   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_auc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48773670196533203   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05385681614279747   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.896951675415039    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(model, ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed5a4a-4078-4be8-be2d-2a7bd11678d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9925</th>\n",
       "      <th>9926</th>\n",
       "      <th>9927</th>\n",
       "      <th>9928</th>\n",
       "      <th>9929</th>\n",
       "      <th>9930</th>\n",
       "      <th>9931</th>\n",
       "      <th>9932</th>\n",
       "      <th>9933</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1815.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoRegressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1189.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoTheta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1120.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoMFLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3260.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>3490.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoMFLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30218</th>\n",
       "      <td>1498.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30219</th>\n",
       "      <td>3049.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>3083.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30220</th>\n",
       "      <td>2470.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30221</th>\n",
       "      <td>6430.0</td>\n",
       "      <td>6340.0</td>\n",
       "      <td>6390.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>6460.0</td>\n",
       "      <td>6520.0</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30223 rows × 9934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1       2       3       4       5       6       7       8       9  \\\n",
       "0      1815.0  1618.0  1598.0  1570.0  1520.0  1600.0  1570.0  1494.0  1367.0   \n",
       "1      1189.0  1225.0  1233.0  1264.0  1445.0  1595.0  1718.0  1668.0  1700.0   \n",
       "2      1120.0  1060.0  1510.0  1630.0  1780.0  1520.0  1530.0  1700.0  1550.0   \n",
       "3      3260.0  2770.0  2890.0  3310.0  3440.0  3700.0  3900.0  3870.0  3490.0   \n",
       "4      2590.0  2510.0  2980.0  2370.0  2220.0  2340.0  2010.0  1960.0  1760.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "30218  1498.0  1503.0  1516.0  1534.0  1536.0  1530.0  1556.0  1565.0  1558.0   \n",
       "30219  3049.0  3056.0  3083.0  3084.0  3100.0  3157.0  3153.0  3162.0  3135.0   \n",
       "30220  2470.0  2390.0  2400.0  2370.0  2390.0  2420.0  2420.0  2390.0  2450.0   \n",
       "30221  6430.0  6340.0  6390.0  6300.0  6360.0  6460.0  6520.0  6480.0  6400.0   \n",
       "30222  1800.0  1790.0  1800.0  1800.0  1810.0  1830.0  1820.0  1810.0  1830.0   \n",
       "\n",
       "           10  ...  9925  9926  9927  9928  9929  9930  9931  9932  9933  \\\n",
       "0      1520.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1      1712.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2      1910.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3      3010.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4      2000.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...       ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "30218  1562.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30219  3093.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30220  2390.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30221  6430.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "30222  1830.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "           best_model  \n",
       "0      AutoRegressive  \n",
       "1           AutoTheta  \n",
       "2           AutoMFLES  \n",
       "3                 CES  \n",
       "4           AutoMFLES  \n",
       "...               ...  \n",
       "30218             CES  \n",
       "30219         AutoETS  \n",
       "30220       AutoARIMA  \n",
       "30221             CES  \n",
       "30222             CES  \n",
       "\n",
       "[30223 rows x 9934 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19eb4b4-889c-4aad-abdc-85a26635288b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
